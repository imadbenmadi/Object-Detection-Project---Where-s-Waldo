{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplified Where's Waldo Object Detection - Kaggle/Google Colab Execution Version\n",
    "\n",
    "Here's a fully executable version of the notebook optimized for Google Colab or Kaggle. I've streamlined the code, reduced computational requirements, and made it more robust for cloud execution:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # Simplified Object Detection: Finding Waldo Characters\n",
    "# \n",
    "# This notebook implements a complete object detection pipeline that:\n",
    "# 1. Creates a synthetic dataset of Waldo characters on backgrounds\n",
    "# 2. Builds a custom object detection model with a ResNet backbone\n",
    "# 3. Trains the model with early stopping and learning rate scheduling\n",
    "# 4. Evaluates performance using precision, recall, IoU and other metrics\n",
    "# 5. Fine-tunes a YOLOv8 model on the same dataset for comparison\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Install Requirements and Import Libraries\n",
    "\n",
    "# %%\n",
    "# Install required packages\n",
    "# !pip install -q ultralytics torch torchvision matplotlib tqdm\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import random\n",
    "import time\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Download and Prepare Character Images\n",
    "\n",
    "# %%\n",
    "# Set up directories\n",
    "object_dir = \"objects\"\n",
    "background_dir = \"backgrounds\"\n",
    "dataset_dir = \"dataset\"\n",
    "\n",
    "os.makedirs(object_dir, exist_ok=True)\n",
    "os.makedirs(background_dir, exist_ok=True)\n",
    "\n",
    "# Download the Waldo character images\n",
    "def download_character_images():\n",
    "    # Waldo character URLs\n",
    "    character_urls = {\n",
    "        \"waldo\": \"https://static.wikia.nocookie.net/waldo/images/9/9d/Character.Waldo.jpg\",\n",
    "        \"wilma\": \"https://static.wikia.nocookie.net/waldo/images/8/86/Character.Wilma.jpg\",\n",
    "        \"wenda\": \"https://static.wikia.nocookie.net/waldo/images/3/3e/Character.Wenda.jpg\"\n",
    "    }\n",
    "    \n",
    "    object_images = []\n",
    "    object_names = []\n",
    "    \n",
    "    for name, url in character_urls.items():\n",
    "        try:\n",
    "            # Download image\n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"‚ö†Ô∏è Failed to download {name}. Creating fallback.\")\n",
    "                create_fallback_character(name, object_dir)\n",
    "                continue\n",
    "                \n",
    "            # Create character image with transparent background\n",
    "            img = Image.open(io.BytesIO(response.content)).convert(\"RGBA\")\n",
    "            \n",
    "            # Simple background removal (white to transparent)\n",
    "            data = np.array(img)\n",
    "            r, g, b, a = data.T\n",
    "            white_areas = (r > 200) & (g > 200) & (b > 200)\n",
    "            data[..., 3][white_areas.T] = 0\n",
    "            \n",
    "            # Save image\n",
    "            transparent_img = Image.fromarray(data)\n",
    "            img_path = os.path.join(object_dir, f\"{name}.png\")\n",
    "            transparent_img.save(img_path)\n",
    "            \n",
    "            object_images.append(transparent_img)\n",
    "            object_names.append(name)\n",
    "            print(f\"‚úÖ Downloaded {name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {name}: {e}\")\n",
    "            create_fallback_character(name, object_dir)\n",
    "    \n",
    "    return object_images, object_names\n",
    "\n",
    "def create_fallback_character(character, output_dir):\n",
    "    \"\"\"Create a simple colored character if download fails\"\"\"\n",
    "    colors = {\n",
    "        \"waldo\": (255, 0, 0, 255),  # Red\n",
    "        \"wilma\": (0, 0, 255, 255),  # Blue\n",
    "        \"wenda\": (255, 105, 180, 255)  # Pink\n",
    "    }\n",
    "    \n",
    "    color = colors.get(character, (255, 165, 0, 255))\n",
    "    \n",
    "    # Create a character silhouette\n",
    "    img = Image.new('RGBA', (200, 300), (0, 0, 0, 0))\n",
    "    \n",
    "    # Draw simple character\n",
    "    from PIL import ImageDraw\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Head\n",
    "    draw.ellipse((75, 30, 125, 80), fill=color)\n",
    "    \n",
    "    # Body\n",
    "    draw.rectangle((85, 80, 115, 180), fill=color)\n",
    "    \n",
    "    # Arms\n",
    "    draw.rectangle((50, 100, 85, 120), fill=color)\n",
    "    draw.rectangle((115, 100, 150, 120), fill=color)\n",
    "    \n",
    "    # Legs\n",
    "    draw.rectangle((85, 180, 95, 250), fill=color)\n",
    "    draw.rectangle((105, 180, 115, 250), fill=color)\n",
    "    \n",
    "    # Add stripes if it's Waldo\n",
    "    if character == \"waldo\":\n",
    "        stripe_color = (255, 255, 255, 255)\n",
    "        for y in range(80, 180, 20):\n",
    "            draw.rectangle((85, y, 115, y+10), fill=stripe_color)\n",
    "    \n",
    "    # Save image\n",
    "    img_path = os.path.join(output_dir, f\"{character}.png\")\n",
    "    img.save(img_path)\n",
    "    print(f\"üé® Created fallback image for {character}\")\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Visualize the characters\n",
    "def visualize_objects(object_images, object_names):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, (img, name) in enumerate(zip(object_images, object_names)):\n",
    "        plt.subplot(1, len(object_images), i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(name)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Download and visualize characters\n",
    "object_images, object_names = download_character_images()\n",
    "visualize_objects(object_images, object_names)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Create Background Images\n",
    "\n",
    "# %%\n",
    "# Create procedural backgrounds (to avoid web crawling on Kaggle/Colab)\n",
    "def create_background_images(num_images=200):\n",
    "    \"\"\"Generate procedural background images\"\"\"\n",
    "    print(f\"Creating {num_images} background images...\")\n",
    "    \n",
    "    background_paths = []\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Create a procedural background with random patterns\n",
    "        bg_width, bg_height = 640, 640\n",
    "        background = Image.new(\"RGB\", (bg_width, bg_height), (255, 255, 255))\n",
    "        \n",
    "        # Draw random shapes for more complex backgrounds\n",
    "        from PIL import ImageDraw\n",
    "        draw = ImageDraw.Draw(background)\n",
    "        \n",
    "        # Add random lines\n",
    "        for _ in range(random.randint(10, 30)):\n",
    "            x1 = random.randint(0, bg_width)\n",
    "            y1 = random.randint(0, bg_height)\n",
    "            x2 = random.randint(0, bg_width)\n",
    "            y2 = random.randint(0, bg_height)\n",
    "            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            width = random.randint(1, 5)\n",
    "            draw.line([(x1, y1), (x2, y2)], fill=color, width=width)\n",
    "        \n",
    "        # Add random rectangles\n",
    "        for _ in range(random.randint(5, 15)):\n",
    "            x1 = random.randint(0, bg_width)\n",
    "            y1 = random.randint(0, bg_height)\n",
    "            x2 = random.randint(0, bg_width)\n",
    "            y2 = random.randint(0, bg_height)\n",
    "            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            draw.rectangle([x1, y1, x2, y2], fill=color)\n",
    "        \n",
    "        # Add random circles\n",
    "        for _ in range(random.randint(5, 15)):\n",
    "            x1 = random.randint(0, bg_width)\n",
    "            y1 = random.randint(0, bg_height)\n",
    "            radius = random.randint(5, 50)\n",
    "            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            draw.ellipse([x1-radius, y1-radius, x1+radius, y1+radius], fill=color)\n",
    "        \n",
    "        # Save the background\n",
    "        bg_path = os.path.join(background_dir, f\"background_{i:03d}.jpg\")\n",
    "        background.save(bg_path)\n",
    "        background_paths.append(bg_path)\n",
    "        \n",
    "        # Show progress\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"  Created {i+1}/{num_images} backgrounds\")\n",
    "    \n",
    "    print(f\"‚úÖ Created {num_images} background images\")\n",
    "    return background_paths\n",
    "\n",
    "# Visualize backgrounds\n",
    "def visualize_backgrounds(background_paths, num_samples=8):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    samples = random.sample(background_paths, min(num_samples, len(background_paths)))\n",
    "    \n",
    "    for i, path in enumerate(samples):\n",
    "        img = Image.open(path)\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Background {i+1}\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate and visualize backgrounds\n",
    "background_paths = create_background_images(200)\n",
    "visualize_backgrounds(background_paths)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Create Synthetic Dataset\n",
    "\n",
    "# %%\n",
    "def create_synthetic_dataset(background_paths, object_images, object_names, \n",
    "                            output_dir, split, img_size=(640, 640), num_images=500):\n",
    "    \"\"\"\n",
    "    Create a synthetic dataset by placing objects on backgrounds\n",
    "    \n",
    "    Parameters:\n",
    "        background_paths: List of paths to background images\n",
    "        object_images: List of object images with transparency\n",
    "        object_names: List of object class names\n",
    "        output_dir: Root directory to save dataset\n",
    "        split: Dataset split ('train', 'val', or 'test')\n",
    "        img_size: Size of output images (width, height)\n",
    "        num_images: Number of images to generate\n",
    "    \"\"\"\n",
    "    # Create directory structure\n",
    "    dataset_dir = os.path.join(output_dir, split)\n",
    "    images_dir = os.path.join(dataset_dir, \"images\")\n",
    "    labels_dir = os.path.join(dataset_dir, \"labels\")\n",
    "    \n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"üéØ Creating {num_images} synthetic images for {split} set...\")\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Select random background\n",
    "        bg_path = random.choice(background_paths)\n",
    "        try:\n",
    "            background = Image.open(bg_path).convert(\"RGB\").resize(img_size)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading background {bg_path}: {e}\")\n",
    "            # Create a simple background as fallback\n",
    "            background = Image.new(\"RGB\", img_size, (200, 200, 200))\n",
    "            \n",
    "        # Select random object\n",
    "        obj_idx = random.randint(0, len(object_images) - 1)\n",
    "        obj_image = object_images[obj_idx].copy()\n",
    "        \n",
    "        # Resize object to random size\n",
    "        scale_factor = random.uniform(0.1, 0.3)  # Object will be 10-30% of image size\n",
    "        obj_width = int(img_size[0] * scale_factor)\n",
    "        obj_height = int(obj_width * (obj_image.height / obj_image.width))  # Maintain aspect ratio\n",
    "        \n",
    "        try:\n",
    "            # For newer PIL versions\n",
    "            obj_image = obj_image.resize((obj_width, obj_height), Image.Resampling.LANCZOS)\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                # For older PIL versions\n",
    "                obj_image = obj_image.resize((obj_width, obj_height), Image.LANCZOS)\n",
    "            except:\n",
    "                # Fallback\n",
    "                obj_image = obj_image.resize((obj_width, obj_height))\n",
    "                \n",
    "        # Place object at random position\n",
    "        max_x = img_size[0] - obj_width\n",
    "        max_y = img_size[1] - obj_height\n",
    "        x_pos = random.randint(0, max_x)\n",
    "        y_pos = random.randint(0, max_y)\n",
    "        \n",
    "        # Paste object on background\n",
    "        background.paste(obj_image, (x_pos, y_pos), obj_image)\n",
    "        \n",
    "        # Calculate YOLO format bounding box\n",
    "        x_center = (x_pos + obj_width / 2) / img_size[0]\n",
    "        y_center = (y_pos + obj_height / 2) / img_size[1]\n",
    "        width = obj_width / img_size[0]\n",
    "        height = obj_height / img_size[1]\n",
    "        \n",
    "        # Save image with proper padding in filename\n",
    "        img_filename = f\"{i:05d}.jpg\"\n",
    "        background.save(os.path.join(images_dir, img_filename))\n",
    "        \n",
    "        # Save label in YOLO format\n",
    "        label_filename = f\"{i:05d}.txt\"\n",
    "        with open(os.path.join(labels_dir, label_filename), \"w\") as f:\n",
    "            f.write(f\"{obj_idx} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "            \n",
    "        # Show progress\n",
    "        if (i + 1) % 100 == 0 or i == num_images - 1:\n",
    "            print(f\"  Progress: {i+1}/{num_images} images created\")\n",
    "    \n",
    "    print(f\"‚úÖ Created {split} dataset with {num_images} images\")\n",
    "    return images_dir, labels_dir\n",
    "\n",
    "# Create all datasets\n",
    "def create_all_datasets(background_paths, object_images, object_names, output_dir=\"dataset\"):\n",
    "    \"\"\"Create train, validation, and test datasets\"\"\"\n",
    "    # Reduced dataset sizes for quicker execution in Colab/Kaggle\n",
    "    train_images, train_labels = create_synthetic_dataset(\n",
    "        background_paths, object_images, object_names, \n",
    "        output_dir, \"train\", num_images=1000\n",
    "    )\n",
    "    \n",
    "    val_images, val_labels = create_synthetic_dataset(\n",
    "        background_paths, object_images, object_names, \n",
    "        output_dir, \"val\", num_images=200\n",
    "    )\n",
    "    \n",
    "    test_images, test_labels = create_synthetic_dataset(\n",
    "        background_paths, object_images, object_names, \n",
    "        output_dir, \"test\", num_images=100\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'train': (train_images, train_labels),\n",
    "        'val': (val_images, val_labels),\n",
    "        'test': (test_images, test_labels)\n",
    "    }\n",
    "\n",
    "# Create the datasets\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "dataset_paths = create_all_datasets(background_paths, object_images, object_names, dataset_dir)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Define Dataset and Create DataLoaders\n",
    "\n",
    "# %%\n",
    "# Define the PyTorch Dataset class\n",
    "class ObjectDetectionDataset(Dataset):\n",
    "    def __init__(self, root_dir, split, num_classes, transform=None):\n",
    "        \"\"\"\n",
    "        Dataset for object detection\n",
    "        \n",
    "        Parameters:\n",
    "            root_dir: Root directory of the dataset\n",
    "            split: 'train', 'val', or 'test'\n",
    "            num_classes: Number of object classes\n",
    "            transform: PyTorch transformations to apply\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.num_classes = num_classes\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get the paths\n",
    "        self.images_dir = os.path.join(root_dir, split, \"images\")\n",
    "        self.labels_dir = os.path.join(root_dir, split, \"labels\")\n",
    "        \n",
    "        # Get image files\n",
    "        self.image_files = sorted([\n",
    "            f for f in os.listdir(self.images_dir) \n",
    "            if f.endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.images_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Get corresponding label\n",
    "        label_path = os.path.join(self.labels_dir, \n",
    "                                  os.path.splitext(self.image_files[idx])[0] + \".txt\")\n",
    "        \n",
    "        # Default values in case label is missing\n",
    "        class_id = 0\n",
    "        bbox = torch.tensor([0.5, 0.5, 0.2, 0.2])  # [x_center, y_center, width, height]\n",
    "        \n",
    "        # Try to load label\n",
    "        try:\n",
    "            with open(label_path, \"r\") as f:\n",
    "                label_data = f.readline().strip().split()\n",
    "                class_id = int(float(label_data[0]))\n",
    "                bbox = torch.tensor([float(x) for x in label_data[1:5]])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading label for {self.image_files[idx]}: {e}\")\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, bbox, class_id\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = ObjectDetectionDataset(dataset_dir, \"train\", len(object_names), train_transform)\n",
    "val_dataset = ObjectDetectionDataset(dataset_dir, \"val\", len(object_names), val_transform)\n",
    "test_dataset = ObjectDetectionDataset(dataset_dir, \"test\", len(object_names), test_transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"‚úÖ DataLoaders created\")\n",
    "print(f\"  ‚Ä¢ Train: {len(train_dataset)} images ({len(train_loader)} batches)\")\n",
    "print(f\"  ‚Ä¢ Val: {len(val_dataset)} images ({len(val_loader)} batches)\")\n",
    "print(f\"  ‚Ä¢ Test: {len(test_dataset)} images ({len(test_loader)} batches)\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Visualize Training Samples\n",
    "\n",
    "# %%\n",
    "# Visualize dataset samples\n",
    "def visualize_dataset_sample(dataset, num_samples=4):\n",
    "    \"\"\"Visualize samples from the dataset\"\"\"\n",
    "    if len(dataset) == 0:\n",
    "        print(\"‚ùå No images in dataset to visualize\")\n",
    "        return\n",
    "        \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        image, bbox, class_id = dataset[i]\n",
    "        \n",
    "        # Denormalize the image\n",
    "        img = image.permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Extract bounding box\n",
    "        x_center, y_center, width, height = bbox.numpy()\n",
    "        \n",
    "        # Calculate bounding box corners\n",
    "        x_min = (x_center - width/2) * img.shape[1]\n",
    "        y_min = (y_center - height/2) * img.shape[0]\n",
    "        x_max = (x_center + width/2) * img.shape[1]\n",
    "        y_max = (y_center + height/2) * img.shape[0]\n",
    "        \n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Class: {object_names[class_id]}\")\n",
    "        \n",
    "        # Draw bounding box\n",
    "        rect = plt.Rectangle((x_min, y_min), x_max-x_min, y_max-y_min, \n",
    "                           fill=False, edgecolor='red', linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from each dataset\n",
    "print(\"üñºÔ∏è Visualizing training samples:\")\n",
    "visualize_dataset_sample(train_dataset)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Build Custom Object Detection Model\n",
    "\n",
    "# %%\n",
    "# Define the custom object detection model with a pre-trained backbone\n",
    "class CustomObjectDetectionModel(nn.Module):\n",
    "    def __init__(self, num_classes=3, pretrained=True):\n",
    "        super(CustomObjectDetectionModel, self).__init__()\n",
    "        # Use a pre-trained ResNet18 as the backbone\n",
    "        resnet = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Remove the final fully connected layer and avgpool\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        \n",
    "        # Feature pyramid to handle multi-scale detection\n",
    "        self.conv1x1 = nn.Conv2d(512, 256, kernel_size=1)  # Reduce channels\n",
    "        \n",
    "        # Add spatial pyramid pooling to handle various object sizes\n",
    "        self.spp = nn.Sequential(\n",
    "            nn.AdaptiveMaxPool2d(5),  # Multi-scale features\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # Feature size after SPP and flattening\n",
    "        feature_size = 5 * 5 * 256\n",
    "        \n",
    "        # Classification head\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.Linear(feature_size, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),  # Add dropout for regularization\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Bounding box regression head\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(feature_size, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),  # Add dropout for regularization\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 4),  # [x_center, y_center, width, height]\n",
    "            nn.Sigmoid()  # Bound outputs between 0 and 1 for normalized coordinates\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        # Initialize the weights of our added layers \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features from the backbone\n",
    "        features = self.backbone(x) \n",
    "        \n",
    "        # Apply 1x1 convolution to reduce channels\n",
    "        features = self.conv1x1(features)\n",
    "        \n",
    "        # Apply spatial pyramid pooling\n",
    "        features_flat = self.spp(features)\n",
    "        \n",
    "        # Process features through the classification and regression heads\n",
    "        class_logits = self.classification_head(features_flat)\n",
    "        bbox_coords = self.regression_head(features_flat)\n",
    "        \n",
    "        return class_logits, bbox_coords\n",
    "\n",
    "# Create the model\n",
    "num_classes = len(object_names)\n",
    "model = CustomObjectDetectionModel(num_classes=num_classes, pretrained=True).to(device)\n",
    "\n",
    "# Print model info\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")\n",
    "print(f\"Model created with {len(object_names)} classes\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Define Loss Function and Optimizer\n",
    "\n",
    "# %%\n",
    "# Define the loss functions\n",
    "classification_loss_fn = nn.CrossEntropyLoss()  # For class probabilities\n",
    "regression_loss_fn = nn.SmoothL1Loss()  # Better choice for bounding box regression than MSE\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Learning rate scheduler to reduce LR when training plateaus\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# Define a custom combined loss function\n",
    "def object_detection_loss(class_pred, bbox_pred, class_target, bbox_target):\n",
    "    \"\"\"\n",
    "    Calculate combined loss for object detection\n",
    "    \n",
    "    Args:\n",
    "        class_pred: predicted class scores [batch_size, num_classes]\n",
    "        bbox_pred: predicted bounding boxes [batch_size, 4]\n",
    "        class_target: ground truth class indices [batch_size]\n",
    "        bbox_target: ground truth bounding boxes [batch_size, 4]\n",
    "    \n",
    "    Returns:\n",
    "        total_loss: combined classification and regression loss\n",
    "        cls_loss: classification loss component\n",
    "        reg_loss: regression loss component\n",
    "    \"\"\"\n",
    "    # Calculate classification loss\n",
    "    cls_loss = classification_loss_fn(class_pred, class_target)\n",
    "    \n",
    "    # Calculate regression loss\n",
    "    reg_loss = regression_loss_fn(bbox_pred, bbox_target)\n",
    "    \n",
    "    # Combine losses - balanced weighting\n",
    "    total_loss = cls_loss + reg_loss\n",
    "    \n",
    "    return total_loss, cls_loss, reg_loss\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Train the Model\n",
    "\n",
    "# %%\n",
    "# Function to train the object detection model\n",
    "def train_model(model, train_loader, val_loader, loss_fn, optimizer, scheduler, \n",
    "                num_epochs=10, early_stopping_patience=5, device=device):\n",
    "    \"\"\"\n",
    "    Train the custom object detection model\n",
    "    \n",
    "    Args:\n",
    "        model: The model to train\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        loss_fn: Combined loss function\n",
    "        optimizer: Optimizer for parameter updates\n",
    "        scheduler: Learning rate scheduler\n",
    "        num_epochs: Maximum number of epochs to train\n",
    "        early_stopping_patience: Number of epochs to wait before early stopping\n",
    "        device: Device to train on (cuda/cpu)\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained model\n",
    "        history: Training history (losses, metrics)\n",
    "    \"\"\"\n",
    "    # Initialize history dictionary to track metrics\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_cls_loss': [], 'val_cls_loss': [],\n",
    "        'train_reg_loss': [], 'val_reg_loss': []\n",
    "    }\n",
    "    \n",
    "    # Variables for early stopping and best model tracking\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    best_model_path = 'best_model.pth'\n",
    "    \n",
    "    # Progress bar for epochs\n",
    "    print(f\"üèãÔ∏è Starting training for {num_epochs} epochs...\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_cls_loss = 0.0\n",
    "        train_reg_loss = 0.0\n",
    "        \n",
    "        # Progress bar for training\n",
    "        train_progress = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "        \n",
    "        for i, (images, bboxes, class_ids) in enumerate(train_progress):\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            bboxes = bboxes.to(device)\n",
    "            class_ids = class_ids.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            class_pred, bbox_pred = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss, cls_loss, reg_loss = loss_fn(class_pred, bbox_pred, class_ids, bboxes)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update running losses\n",
    "            train_loss += loss.item()\n",
    "            train_cls_loss += cls_loss.item()\n",
    "            train_reg_loss += reg_loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_progress.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate average training losses\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_train_cls_loss = train_cls_loss / len(train_loader)\n",
    "        avg_train_reg_loss = train_reg_loss / len(train_loader)\n",
    "        \n",
    "        # Add to history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_cls_loss'].append(avg_train_cls_loss)\n",
    "        history['train_reg_loss'].append(avg_train_reg_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_cls_loss = 0.0\n",
    "        val_reg_loss = 0.0\n",
    "        \n",
    "        # Progress bar for validation\n",
    "        val_progress = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (images, bboxes, class_ids) in enumerate(val_progress):\n",
    "                # Move data to device\n",
    "                images = images.to(device)\n",
    "                bboxes = bboxes.to(device)\n",
    "                class_ids = class_ids.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                class_pred, bbox_pred = model(images)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss, cls_loss, reg_loss = loss_fn(class_pred, bbox_pred, class_ids, bboxes)\n",
    "                \n",
    "                # Update running losses\n",
    "                val_loss += loss.item()\n",
    "                val_cls_loss += cls_loss.item()\n",
    "                val_reg_loss += reg_loss.item()\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_progress.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate average validation losses\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_cls_loss = val_cls_loss / len(val_loader)\n",
    "        avg_val_reg_loss = val_reg_loss / len(val_loader)\n",
    "        \n",
    "        # Add to history\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_cls_loss'].append(avg_val_cls_loss)\n",
    "        history['val_reg_loss'].append(avg_val_reg_loss)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f} (Cls: {avg_train_cls_loss:.4f}, Reg: {avg_train_reg_loss:.4f})\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f} (Cls: {avg_val_cls_loss:.4f}, Reg: {avg_val_reg_loss:.4f})\")\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            early_stopping_counter = 0\n",
    "            \n",
    "            # Save the best model\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': best_val_loss,\n",
    "                'history': history\n",
    "            }, best_model_path)\n",
    "            \n",
    "            print(f\"  ‚úÖ Model improved! Saved checkpoint to {best_model_path}\")\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            print(f\"  ‚ö†Ô∏è Model did not improve. Early stopping counter: {early_stopping_counter}/{early_stopping_patience}\")\n",
    "            \n",
    "            # Check if we should stop early\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"  üõë Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"\\n‚úÖ Training complete! Best model from epoch {checkpoint['epoch']} loaded (Val Loss: {checkpoint['val_loss']:.4f})\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Set training parameters - reduced for Colab/Kaggle\n",
    "num_epochs = 10  # Use 20-30 if running on more powerful hardware\n",
    "early_stopping_patience = 3\n",
    "\n",
    "# Start training\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=object_detection_loss,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    early_stopping_patience=early_stopping_patience\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Visualize Training Metrics\n",
    "\n",
    "# %%\n",
    "# Plot the training history\n",
    "def plot_training_metrics(history):\n",
    "    \"\"\"Plot training and validation metrics with analysis\"\"\"\n",
    "    # Create a figure with 2 subplots\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    # Plot total loss (main metric)\n",
    "    axes[0].plot(history['train_loss'], label=\"Training Loss\", color=\"blue\", marker=\"o\")\n",
    "    axes[0].plot(history['val_loss'], label=\"Validation Loss\", color=\"orange\", marker=\"o\")\n",
    "    axes[0].set_ylabel(\"Total Loss\")\n",
    "    axes[0].set_title(\"Training and Validation Loss Over Time\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Add annotations for best model\n",
    "    best_epoch = np.argmin(history['val_loss'])\n",
    "    best_val_loss = history['val_loss'][best_epoch]\n",
    "    axes[0].axvline(x=best_epoch, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[0].scatter(best_epoch, best_val_loss, s=100, c='red', label=f'Best Model (Epoch {best_epoch+1})')\n",
    "    \n",
    "    # Plot component losses (classification and regression)\n",
    "    axes[1].plot(history['train_cls_loss'], label=\"Train Classification Loss\", color=\"blue\", linestyle=\"-\")\n",
    "    axes[1].plot(history['val_cls_loss'], label=\"Val Classification Loss\", color=\"blue\", linestyle=\"--\")\n",
    "    axes[1].plot(history['train_reg_loss'], label=\"Train Regression Loss\", color=\"green\", linestyle=\"-\")\n",
    "    axes[1].plot(history['val_reg_loss'], label=\"Val Regression Loss\", color=\"green\", linestyle=\"--\")\n",
    "    axes[1].set_xlabel(\"Epochs\")\n",
    "    axes[1].set_ylabel(\"Component Losses\")\n",
    "    axes[1].set_title(\"Classification and Regression Loss Components\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze convergence and provide text report\n",
    "    print(\"üìä Model Convergence Analysis:\")\n",
    "    \n",
    "    # Check if the model has converged\n",
    "    min_loss_epoch = np.argmin(history['val_loss'])\n",
    "    last_epoch = len(history['val_loss']) - 1\n",
    "    \n",
    "    # Calculate training and validation loss reduction\n",
    "    initial_train_loss = history['train_loss'][0]\n",
    "    final_train_loss = history['train_loss'][last_epoch]\n",
    "    train_reduction = ((initial_train_loss - final_train_loss) / initial_train_loss) * 100\n",
    "    \n",
    "    initial_val_loss = history['val_loss'][0]\n",
    "    final_val_loss = history['val_loss'][last_epoch]\n",
    "    best_val_loss = history['val_loss'][min_loss_epoch]\n",
    "    val_reduction = ((initial_val_loss - best_val_loss) / initial_val_loss) * 100\n",
    "    \n",
    "    # Check if loss is still decreasing at the end of training\n",
    "    if min_loss_epoch == last_epoch:\n",
    "        print(f\"  ‚Ä¢ The model was STILL IMPROVING when training stopped at epoch {last_epoch+1}\")\n",
    "        print(f\"  ‚Ä¢ Consider training for more epochs to potentially achieve better performance\")\n",
    "    elif min_loss_epoch < last_epoch - 2:\n",
    "        print(f\"  ‚Ä¢ The model CONVERGED around epoch {min_loss_epoch+1} (best validation loss)\")\n",
    "        print(f\"  ‚Ä¢ Early stopping prevented overfitting by loading the best model\")\n",
    "    else:\n",
    "        print(f\"  ‚Ä¢ The model appears to have CONVERGED near the end of training (best at epoch {min_loss_epoch+1})\")\n",
    "    \n",
    "    print(f\"\\n  ‚Ä¢ Training loss reduced by {train_reduction:.2f}% (from {initial_train_loss:.4f} to {final_train_loss:.4f})\")\n",
    "    print(f\"  ‚Ä¢ Validation loss reduced by {val_reduction:.2f}% (from {initial_val_loss:.4f} to {best_val_loss:.4f})\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    if final_train_loss < final_val_loss * 0.7:\n",
    "        print(\"\\n  ‚ö†Ô∏è OVERFITTING DETECTED: The training loss is much lower than validation loss\")\n",
    "    else:\n",
    "        print(\"\\n  ‚úÖ HEALTHY CONVERGENCE: Training and validation losses decreased together\")\n",
    "        print(\"  ‚Ä¢ The model appears to generalize well to unseen data\")\n",
    "\n",
    "# Plot training metrics\n",
    "plot_training_metrics(history)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. Evaluate the Custom Model\n",
    "\n",
    "# %%\n",
    "# Function to calculate Intersection over Union (IoU)\n",
    "def calculate_iou(pred_box, true_box):\n",
    "    \"\"\"Calculate IoU between predicted and ground truth boxes in YOLO format\"\"\"\n",
    "    # Extract coordinates (convert from center format to corner format)\n",
    "    pred_x1 = pred_box[0] - pred_box[2] / 2\n",
    "    pred_y1 = pred_box[1] - pred_box[3] / 2\n",
    "    pred_x2 = pred_box[0] + pred_box[2] / 2\n",
    "    pred_y2 = pred_box[1] + pred_box[3] / 2\n",
    "\n",
    "    true_x1 = true_box[0] - true_box[2] / 2\n",
    "    true_y1 = true_box[1] - true_box[3] / 2\n",
    "    true_x2 = true_box[0] + true_box[2] / 2\n",
    "    true_y2 = true_box[1] + true_box[3] / 2\n",
    "\n",
    "    # Calculate intersection area\n",
    "    inter_x1 = max(pred_x1, true_x1)\n",
    "    inter_y1 = max(pred_y1, true_y1)\n",
    "    inter_x2 = min(pred_x2, true_x2)\n",
    "    inter_y2 = min(pred_y2, true_y2)\n",
    "\n",
    "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "\n",
    "    # Calculate union area\n",
    "    pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)\n",
    "    true_area = (true_x2 - true_x1) * (true_y2 - true_y1)\n",
    "    union_area = pred_area + true_area - inter_area\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return inter_area / union_area\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def evaluate_model(model, test_loader, device, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test data with multiple metrics\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Initialize metrics\n",
    "    metrics = {\n",
    "        'precision': [], 'recall': [], 'f1': [], 'iou': [],\n",
    "        'class_accuracy': [], 'inference_times': []\n",
    "    }\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    class_metrics = {class_name: {'correct': 0, 'total': 0} \n",
    "                    for class_name in object_names}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, true_boxes, true_classes in test_loader:\n",
    "            images = images.to(device)\n",
    "            true_boxes = true_boxes.to(device)\n",
    "            true_classes = true_classes.to(device)\n",
    "            \n",
    "            # Measure inference time\n",
    "            start_time = time.time()\n",
    "            class_logits, pred_boxes = model(images)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Calculate inference time per image\n",
    "            batch_inference_time = (end_time - start_time) / len(images)\n",
    "            metrics['inference_times'].append(batch_inference_time)\n",
    "            \n",
    "            # Get predicted classes\n",
    "            _, pred_classes = torch.max(class_logits, 1)\n",
    "            \n",
    "            # Calculate metrics for each image in the batch\n",
    "            for i in range(len(images)):\n",
    "                pred_box = pred_boxes[i].cpu().numpy()\n",
    "                true_box = true_boxes[i].cpu().numpy()\n",
    "                \n",
    "                # Calculate IoU\n",
    "                iou = calculate_iou(pred_box, true_box)\n",
    "                metrics['iou'].append(iou)\n",
    "                \n",
    "                # Class prediction accuracy\n",
    "                pred_class = pred_classes[i].item()\n",
    "                true_class = true_classes[i].item()\n",
    "                class_correct = (pred_class == true_class)\n",
    "                metrics['class_accuracy'].append(float(class_correct))\n",
    "                \n",
    "                # Update class-specific metrics\n",
    "                class_name = object_names[true_class]\n",
    "                class_metrics[class_name]['total'] += 1\n",
    "                if class_correct:\n",
    "                    class_metrics[class_name]['correct'] += 1\n",
    "                \n",
    "                # Calculate precision, recall, and F1-score\n",
    "                # Detection is correct if IoU > threshold AND class is correct\n",
    "                correct_detection = (iou > iou_threshold) and class_correct\n",
    "                \n",
    "                if correct_detection:\n",
    "                    precision = 1.0\n",
    "                    recall = 1.0\n",
    "                else:\n",
    "                    precision = 0.0\n",
    "                    recall = 0.0\n",
    "                \n",
    "                f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "                \n",
    "                metrics['precision'].append(precision)\n",
    "                metrics['recall'].append(recall)\n",
    "                metrics['f1'].append(f1)\n",
    "    \n",
    "    # Calculate mean metrics\n",
    "    mean_metrics = {\n",
    "        'precision': np.mean(metrics['precision']),\n",
    "        'recall': np.mean(metrics['recall']),\n",
    "        'f1': np.mean(metrics['f1']),\n",
    "        'iou': np.mean(metrics['iou']),\n",
    "        'class_accuracy': np.mean(metrics['class_accuracy']),\n",
    "        'inference_time': np.mean(metrics['inference_times'])\n",
    "    }\n",
    "    \n",
    "    # Calculate class-specific accuracy\n",
    "    for class_name in class_metrics:\n",
    "        total = class_metrics[class_name]['total']\n",
    "        if total > 0:\n",
    "            class_metrics[class_name]['accuracy'] = class_metrics[class_name]['correct'] / total\n",
    "        else:\n",
    "            class_metrics[class_name]['accuracy'] = 0.0\n",
    "    \n",
    "    # Calculate model size\n",
    "    model_size_bytes = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
    "    model_size_mb = model_size_bytes / (1024 * 1024)\n",
    "    \n",
    "    # Print metrics summary\n",
    "    print(\"\\nüìä Model Evaluation Metrics:\")\n",
    "    print(f\"  ‚Ä¢ Mean Precision: {mean_metrics['precision']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Mean Recall: {mean_metrics['recall']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Mean F1-Score: {mean_metrics['f1']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Mean IoU: {mean_metrics['iou']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Class Prediction Accuracy: {mean_metrics['class_accuracy']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Average Inference Time: {mean_metrics['inference_time']*1000:.2f} ms per image\")\n",
    "    print(f\"  ‚Ä¢ Model Size: {model_size_mb:.2f} MB\")\n",
    "    \n",
    "    # Print class-specific metrics\n",
    "    print(\"\\nüìä Class-Specific Metrics:\")\n",
    "    for class_name in class_metrics:\n",
    "        accuracy = class_metrics[class_name]['accuracy']\n",
    "        total = class_metrics[class_name]['total']\n",
    "        print(f\"  ‚Ä¢ {class_name}: Accuracy = {accuracy:.4f} (from {total} samples)\")\n",
    "    \n",
    "    return mean_metrics, class_metrics\n",
    "\n",
    "# Run evaluation on the test set\n",
    "mean_metrics, class_metrics = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12. Visualize Custom Model Predictions\n",
    "\n",
    "# %%\n",
    "# Visualize predictions on test images\n",
    "def visualize_predictions(model, test_loader, device, num_images=8):\n",
    "    \"\"\"\n",
    "    Visualize model predictions vs ground truth with detailed metrics\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Get a batch from the test loader\n",
    "    data_iter = iter(test_loader)\n",
    "    images, true_boxes, true_classes = next(data_iter)\n",
    "    \n",
    "    # Ensure we don't try to visualize more images than we have\n",
    "    num_images = min(num_images, len(images))\n",
    "    \n",
    "    # Make predictions\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        class_logits, pred_boxes = model(images)\n",
    "        _, pred_classes = torch.max(class_logits, 1)\n",
    "    \n",
    "    # Set up the plot\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Get image and convert for display\n",
    "        img = images[i].cpu()\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Get ground truth box and class\n",
    "        true_box = true_boxes[i].cpu().numpy()\n",
    "        true_class = true_classes[i].item()\n",
    "        true_class_name = object_names[true_class]\n",
    "        \n",
    "        # Get predicted box and class\n",
    "        pred_box = pred_boxes[i].cpu().numpy()\n",
    "        pred_class = pred_classes[i].item()\n",
    "        pred_class_name = object_names[pred_class]\n",
    "        \n",
    "        # Calculate IoU\n",
    "        iou = calculate_iou(pred_box, true_box)\n",
    "        \n",
    "        # Plot the image\n",
    "        axes[i].imshow(img)\n",
    "        \n",
    "        # Draw ground truth box (green)\n",
    "        x_center, y_center, width, height = true_box\n",
    "        x_min = (x_center - width/2) * img.shape[1]\n",
    "        y_min = (y_center - height/2) * img.shape[0]\n",
    "        x_max = (x_center + width/2) * img.shape[1]\n",
    "        y_max = (y_center + height/2) * img.shape[0]\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), x_max-x_min, y_max-y_min,\n",
    "            linewidth=2, edgecolor='green', facecolor='none', label='True'\n",
    "        )\n",
    "        axes[i].add_patch(rect)\n",
    "        \n",
    "        # Draw predicted box (red)\n",
    "        x_center, y_center, width, height = pred_box\n",
    "        x_min = (x_center - width/2) * img.shape[1]\n",
    "        y_min = (y_center - height/2) * img.shape[0]\n",
    "        x_max = (x_center + width/2) * img.shape[1]\n",
    "        y_max = (y_center + height/2) * img.shape[0]\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), x_max-x_min, y_max-y_min,\n",
    "            linewidth=2, edgecolor='red', facecolor='none', label='Pred'\n",
    "        )\n",
    "        axes[i].add_patch(rect)\n",
    "        \n",
    "        # Add detailed title with metrics\n",
    "        axes[i].set_title(\n",
    "            f\"True: {true_class_name}, Pred: {pred_class_name}\\nIoU: {iou:.2f}\",\n",
    "            fontsize=10\n",
    "        )\n",
    "        axes[i].axis('off')\n",
    "        axes[i].legend()\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Model Predictions vs Ground Truth\", fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(model, test_loader, device)\n",
    "\n",
    "# Visualize predictions on test images with detailed metrics\n",
    "def visualize_predictions_with_metrics(model, test_loader, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Visualize model predictions on test images with detailed metrics\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Get a batch of images from the test loader\n",
    "    images, true_boxes, true_classes = next(iter(test_loader))\n",
    "    images, true_boxes, true_classes = images.to(device), true_boxes.to(device), true_classes.to(device)\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        class_logits, pred_boxes = model(images)\n",
    "        _, pred_classes = torch.max(class_logits, 1)\n",
    "\n",
    "    # Set up figure for visualization\n",
    "    num_images = min(8, len(images))\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Get current image and denormalize it properly\n",
    "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Display the image\n",
    "        axes[i].imshow(img)\n",
    "\n",
    "        # Get ground truth and prediction information\n",
    "        true_box = true_boxes[i].cpu().numpy()\n",
    "        pred_box = pred_boxes[i].cpu().numpy()\n",
    "        true_class = true_classes[i].item()\n",
    "        pred_class = pred_classes[i].item()\n",
    "        \n",
    "        # Get class names\n",
    "        true_class_name = object_names[true_class]\n",
    "        pred_class_name = object_names[pred_class]\n",
    "\n",
    "        # Calculate ground truth box coordinates\n",
    "        x_center, y_center, width, height = true_box\n",
    "        x_min = (x_center - width/2) * img.shape[1]\n",
    "        y_min = (y_center - height/2) * img.shape[0]\n",
    "        x_max = (x_center + width/2) * img.shape[1]\n",
    "        y_max = (y_center + height/2) * img.shape[0]\n",
    "        \n",
    "        # Add ground truth box\n",
    "        gt_rect = plt.Rectangle(\n",
    "            (x_min, y_min), x_max-x_min, y_max-y_min, \n",
    "            linewidth=2, edgecolor=\"green\", facecolor=\"none\", \n",
    "            label=f\"True: {true_class_name}\"\n",
    "        )\n",
    "        axes[i].add_patch(gt_rect)\n",
    "\n",
    "        # Calculate predicted box coordinates\n",
    "        x_center, y_center, width, height = pred_box\n",
    "        x_min = (x_center - width/2) * img.shape[1]\n",
    "        y_min = (y_center - height/2) * img.shape[0]\n",
    "        x_max = (x_center + width/2) * img.shape[1]\n",
    "        y_max = (y_center + height/2) * img.shape[0]\n",
    "        \n",
    "        # Add predicted box\n",
    "        pred_rect = plt.Rectangle(\n",
    "            (x_min, y_min), x_max-x_min, y_max-y_min, \n",
    "            linewidth=2, edgecolor=\"red\", facecolor=\"none\", \n",
    "            label=f\"Pred: {pred_class_name}\"\n",
    "        )\n",
    "        axes[i].add_patch(pred_rect)\n",
    "\n",
    "        # Calculate metrics\n",
    "        iou = calculate_iou(pred_box, true_box)\n",
    "        \n",
    "        # Calculate precision and recall based on IoU threshold\n",
    "        class_correct = (pred_class == true_class)\n",
    "        detection_correct = (iou > iou_threshold) and class_correct\n",
    "        \n",
    "        precision = 1.0 if detection_correct else 0.0\n",
    "        recall = 1.0 if detection_correct else 0.0\n",
    "        \n",
    "        # Add metrics annotation\n",
    "        axes[i].set_title(\n",
    "            f\"IoU: {iou:.2f} | Precision: {precision:.1f} | Recall: {recall:.1f}\\n\"\n",
    "            f\"True: {true_class_name} | Pred: {pred_class_name}\", \n",
    "            fontsize=9\n",
    "        )\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].legend(loc=\"upper right\", fontsize=8)\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Model Predictions vs Ground Truth with Metrics\", fontsize=14, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Run the detailed visualization\n",
    "visualize_predictions_with_metrics(model, test_loader)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 13. Fine-tune YOLOv8 on the Same Dataset\n",
    "\n",
    "# %%\n",
    "# Prepare the data.yaml file for YOLO training\n",
    "train_images_path = os.path.join(dataset_dir, \"train\", \"images\")\n",
    "val_images_path = os.path.join(dataset_dir, \"val\", \"images\")\n",
    "test_images_path = os.path.join(dataset_dir, \"test\", \"images\")\n",
    "\n",
    "# Create the data.yaml file in the dataset directory\n",
    "data_yaml_path = os.path.join(dataset_dir, \"data.yaml\")\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    f.write(f\"path: {dataset_dir}\\n\")\n",
    "    f.write(f\"train: {train_images_path}\\n\")\n",
    "    f.write(f\"val: {val_images_path}\\n\")\n",
    "    f.write(f\"test: {test_images_path}\\n\")\n",
    "    f.write(f\"nc: {len(object_names)}\\n\")  # Number of classes from object_names\n",
    "    \n",
    "    # Write class names dynamically from object_names\n",
    "    f.write(\"names:\\n\")\n",
    "    for i, name in enumerate(object_names):\n",
    "        f.write(f\"  {i}: {name}\\n\")\n",
    "\n",
    "print(f\"‚úÖ data.yaml file created at {data_yaml_path}\")\n",
    "print(\"üìÑ Content preview:\")\n",
    "with open(data_yaml_path, \"r\") as f:\n",
    "    print(f.read())\n",
    "\n",
    "# Import YOLO from ultralytics\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    # Load a pre-trained YOLO model\n",
    "    yolo_model = YOLO(\"yolov8n.pt\")  # Using YOLOv8 nano version\n",
    "    \n",
    "    # Print model information\n",
    "    print(f\"\\nüîç Using pre-trained model: YOLOv8n\")\n",
    "    print(f\"  ‚Ä¢ Architecture: YOLOv8 (Detection)\")\n",
    "    print(f\"  ‚Ä¢ Size: Nano (compact)\")\n",
    "    print(f\"  ‚Ä¢ Pre-trained on: COCO dataset (80 classes)\")\n",
    "    \n",
    "    # Fine-tune the YOLO model on the custom dataset\n",
    "    print(\"\\nüèãÔ∏è Starting YOLO model fine-tuning...\")\n",
    "    results = yolo_model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=5,  # Reduced for Colab/Kaggle\n",
    "        imgsz=640,\n",
    "        batch=8,  # Reduced for Colab/Kaggle\n",
    "        patience=3,  # Early stopping patience\n",
    "        save=True,  # Save best model\n",
    "        device=0 if torch.cuda.is_available() else \"cpu\",\n",
    "        project=\"yolo_training\",\n",
    "        name=\"run1\"\n",
    "    )\n",
    "    \n",
    "    # Save the fine-tuned YOLO model\n",
    "    fine_tuned_model_path = \"yolo_fine_tuned.pt\"\n",
    "    yolo_model.export(format=\"pytorch\")  # Export to PyTorch format\n",
    "    \n",
    "    print(f\"‚úÖ Fine-tuned YOLO model saved\")\n",
    "    print(f\"  ‚Ä¢ Best model path: {yolo_model.best}\")\n",
    "    print(f\"  ‚Ä¢ Exported model: {fine_tuned_model_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during YOLO training: {str(e)}\")\n",
    "    print(\"You can continue with the rest of the notebook.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 14. Evaluate YOLO Model\n",
    "\n",
    "# %%\n",
    "# Function to evaluate the YOLO model on the test set\n",
    "def evaluate_yolo_model(yolo_model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate YOLO model on test data and calculate standard metrics\n",
    "    \"\"\"\n",
    "    yolo_model.eval()  # Set YOLO model to evaluation mode\n",
    "    \n",
    "    # Initialize metrics\n",
    "    metrics = {\n",
    "        'precision': [], 'recall': [], 'f1': [], 'iou': [], \n",
    "        'inference_times': []\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, true_boxes, true_classes in test_loader:\n",
    "            # Process each image individually to avoid batching issues\n",
    "            for i in range(len(images)):\n",
    "                # Get single image and convert to numpy with correct format\n",
    "                image = images[i].cpu().numpy().transpose(1, 2, 0)  # CHW to HWC\n",
    "                \n",
    "                # Denormalize the image from [-1,1] to [0,255]\n",
    "                image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                image = np.clip(image, 0, 1) * 255\n",
    "                image = image.astype(np.uint8)\n",
    "                \n",
    "                # Get ground truth\n",
    "                true_box = true_boxes[i].cpu().numpy()\n",
    "                true_class = true_classes[i].item()\n",
    "                \n",
    "                # Measure inference time for single image\n",
    "                start_time = time.time()\n",
    "                # Run inference with YOLO - process one image at a time\n",
    "                try:\n",
    "                    result = yolo_model(image, conf=0.25, iou=0.45)[0]  # Get first (only) result\n",
    "                    end_time = time.time()\n",
    "                    inference_time = end_time - start_time\n",
    "                    metrics['inference_times'].append(inference_time)\n",
    "                    \n",
    "                    # Get YOLO predictions (boxes in xywh normalized format)\n",
    "                    if len(result.boxes) > 0:\n",
    "                        # Convert to xywh normalized format\n",
    "                        pred_box = result.boxes.xywhn[0].cpu().numpy()\n",
    "                        pred_class = int(result.boxes.cls[0].item())\n",
    "                        \n",
    "                        # Calculate IoU between predicted and ground truth box\n",
    "                        iou = calculate_iou(pred_box, true_box)\n",
    "                        metrics['iou'].append(iou)\n",
    "                        \n",
    "                        # Determine if detection is correct (IoU > 0.5 and correct class)\n",
    "                        class_correct = (pred_class == true_class)\n",
    "                        detection_correct = (iou > 0.5) and class_correct\n",
    "                        \n",
    "                        # Calculate precision and recall\n",
    "                        precision = 1.0 if detection_correct else 0.0\n",
    "                        recall = 1.0 if detection_correct else 0.0\n",
    "                        \n",
    "                        # Calculate F1 score\n",
    "                        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "                    else:\n",
    "                        # No detection\n",
    "                        iou = 0.0\n",
    "                        precision = 0.0\n",
    "                        recall = 0.0\n",
    "                        f1 = 0.0\n",
    "                        metrics['iou'].append(iou)\n",
    "                    \n",
    "                    # Store metrics\n",
    "                    metrics['precision'].append(precision)\n",
    "                    metrics['recall'].append(recall)\n",
    "                    metrics['f1'].append(f1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {i}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Calculate mean metrics if we have data\n",
    "    if len(metrics['iou']) > 0:\n",
    "        mean_metrics = {\n",
    "            'precision': np.mean(metrics['precision']),\n",
    "            'recall': np.mean(metrics['recall']),\n",
    "            'f1': np.mean(metrics['f1']),\n",
    "            'iou': np.mean(metrics['iou']),\n",
    "            'inference_time': np.mean(metrics['inference_times'])\n",
    "        }\n",
    "        \n",
    "        # Print detailed evaluation results\n",
    "        print(\"\\nüìä YOLO Model Evaluation Results:\")\n",
    "        print(f\"  ‚Ä¢ Mean Precision: {mean_metrics['precision']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Mean Recall: {mean_metrics['recall']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Mean F1-Score: {mean_metrics['f1']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Mean IoU: {mean_metrics['iou']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Average Inference Time:# %% [markdown]\n",
    "# # Simplified Object Detection: Finding Waldo Characters\n",
    "# \n",
    "# This notebook implements a complete object detection pipeline that:\n",
    "# 1. Creates a synthetic dataset of Waldo characters on backgrounds\n",
    "# 2. Builds a custom object detection model with a ResNet backbone\n",
    "# 3. Trains the model with early stopping and learning rate scheduling\n",
    "# 4. Evaluates performance using precision, recall, IoU and other metrics\n",
    "# 5. Fine-tunes a YOLOv8 model on the same dataset for comparison\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Install Requirements and Import Libraries\n",
    "\n",
    "# %%\n",
    "# Install required packages\n",
    "!pip install -q ultralytics torch torchvision matplotlib tqdm\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import random\n",
    "import time\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Download and Prepare Character Images\n",
    "\n",
    "# %%\n",
    "# Set up directories\n",
    "object_dir = \"objects\"\n",
    "background_dir = \"backgrounds\"\n",
    "dataset_dir = \"dataset\"\n",
    "\n",
    "os.makedirs(object_dir, exist_ok=True)\n",
    "os.makedirs(background_dir, exist_ok=True)\n",
    "\n",
    "# Download the Waldo character images\n",
    "def download_character_images():\n",
    "    # Waldo character URLs\n",
    "    character_urls = {\n",
    "        \"waldo\": \"https://static.wikia.nocookie.net/waldo/images/9/9d/Character.Waldo.jpg\",\n",
    "        \"wilma\": \"https://static.wikia.nocookie.net/waldo/images/8/86/Character.Wilma.jpg\",\n",
    "        \"wenda\": \"https://static.wikia.nocookie.net/waldo/images/3/3e/Character.Wenda.jpg\"\n",
    "    }\n",
    "    \n",
    "    object_images = []\n",
    "    object_names = []\n",
    "    \n",
    "    for name, url in character_urls.items():\n",
    "        try:\n",
    "            # Download image\n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"‚ö†Ô∏è Failed to download {name}. Creating fallback.\")\n",
    "                create_fallback_character(name, object_dir)\n",
    "                continue\n",
    "                \n",
    "            # Create character image with transparent background\n",
    "            img = Image.open(io.BytesIO(response.content)).convert(\"RGBA\")\n",
    "            \n",
    "            # Simple background removal (white to transparent)\n",
    "            data = np.array(img)\n",
    "            r, g, b, a = data.T\n",
    "            white_areas = (r > 200) & (g > 200) & (b > 200)\n",
    "            data[..., 3][white_areas.T] = 0\n",
    "            \n",
    "            # Save image\n",
    "            transparent_img = Image.fromarray(data)\n",
    "            img_path = os.path.join(object_dir, f\"{name}.png\")\n",
    "            transparent_img.save(img_path)\n",
    "            \n",
    "            object_images.append(transparent_img)\n",
    "            object_names.append(name)\n",
    "            print(f\"‚úÖ Downloaded {name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {name}: {e}\")\n",
    "            create_fallback_character(name, object_dir)\n",
    "    \n",
    "    return object_images, object_names\n",
    "\n",
    "def create_fallback_character(character, output_dir):\n",
    "    \"\"\"Create a simple colored character if download fails\"\"\"\n",
    "    colors = {\n",
    "        \"waldo\": (255, 0, 0, 255),  # Red\n",
    "        \"wilma\": (0, 0, 255, 255),  # Blue\n",
    "        \"wenda\": (255, 105, 180, 255)  # Pink\n",
    "    }\n",
    "    \n",
    "    color = colors.get(character, (255, 165, 0, 255))\n",
    "    \n",
    "    # Create a character silhouette\n",
    "    img = Image.new('RGBA', (200, 300), (0, 0, 0, 0))\n",
    "    \n",
    "    # Draw simple character\n",
    "    from PIL import ImageDraw\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # Head\n",
    "    draw.ellipse((75, 30, 125, 80), fill=color)\n",
    "    \n",
    "    # Body\n",
    "    draw.rectangle((85, 80, 115, 180), fill=color)\n",
    "    \n",
    "    # Arms\n",
    "    draw.rectangle((50, 100, 85, 120), fill=color)\n",
    "    draw.rectangle((115, 100, 150, 120), fill=color)\n",
    "    \n",
    "    # Legs\n",
    "    draw.rectangle((85, 180, 95, 250), fill=color)\n",
    "    draw.rectangle((105, 180, 115, 250), fill=color)\n",
    "    \n",
    "    # Add stripes if it's Waldo\n",
    "    if character == \"waldo\":\n",
    "        stripe_color = (255, 255, 255, 255)\n",
    "        for y in range(80, 180, 20):\n",
    "            draw.rectangle((85, y, 115, y+10), fill=stripe_color)\n",
    "    \n",
    "    # Save image\n",
    "    img_path = os.path.join(output_dir, f\"{character}.png\")\n",
    "    img.save(img_path)\n",
    "    print(f\"üé® Created fallback image for {character}\")\n",
    "    \n",
    "    return img\n",
    "\n",
    "# Visualize the characters\n",
    "def visualize_objects(object_images, object_names):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, (img, name) in enumerate(zip(object_images, object_names)):\n",
    "        plt.subplot(1, len(object_images), i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(name)\n",
    "        plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Download and visualize characters\n",
    "object_images, object_names = download_character_images()\n",
    "visualize_objects(object_images, object_names)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Create Background Images\n",
    "\n",
    "# %%\n",
    "# Create procedural backgrounds (to avoid web crawling on Kaggle/Colab)\n",
    "def create_background_images(num_images=200):\n",
    "    \"\"\"Generate procedural background images\"\"\"\n",
    "    print(f\"Creating {num_images} background images...\")\n",
    "    \n",
    "    background_paths = []\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Create a procedural background with random patterns\n",
    "        bg_width, bg_height = 640, 640\n",
    "        background = Image.new(\"RGB\", (bg_width, bg_height), (255, 255, 255))\n",
    "        \n",
    "        # Draw random shapes for more complex backgrounds\n",
    "        from PIL import ImageDraw\n",
    "        draw = ImageDraw.Draw(background)\n",
    "        \n",
    "        # Add random lines\n",
    "        for _ in range(random.randint(10, 30)):\n",
    "            x1 = random.randint(0, bg_width)\n",
    "            y1 = random.randint(0, bg_height)\n",
    "            x2 = random.randint(0, bg_width)\n",
    "            y2 = random.randint(0, bg_height)\n",
    "            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            width = random.randint(1, 5)\n",
    "            draw.line([(x1, y1), (x2, y2)], fill=color, width=width)\n",
    "        \n",
    "        # Add random rectangles\n",
    "        for _ in range(random.randint(5, 15)):\n",
    "            x1 = random.randint(0, bg_width)\n",
    "            y1 = random.randint(0, bg_height)\n",
    "            x2 = random.randint(0, bg_width)\n",
    "            y2 = random.randint(0, bg_height)\n",
    "            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            draw.rectangle([x1, y1, x2, y2], fill=color)\n",
    "        \n",
    "        # Add random circles\n",
    "        for _ in range(random.randint(5, 15)):\n",
    "            x1 = random.randint(0, bg_width)\n",
    "            y1 = random.randint(0, bg_height)\n",
    "            radius = random.randint(5, 50)\n",
    "            color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            draw.ellipse([x1-radius, y1-radius, x1+radius, y1+radius], fill=color)\n",
    "        \n",
    "        # Save the background\n",
    "        bg_path = os.path.join(background_dir, f\"background_{i:03d}.jpg\")\n",
    "        background.save(bg_path)\n",
    "        background_paths.append(bg_path)\n",
    "        \n",
    "        # Show progress\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(f\"  Created {i+1}/{num_images} backgrounds\")\n",
    "    \n",
    "    print(f\"‚úÖ Created {num_images} background images\")\n",
    "    return background_paths\n",
    "\n",
    "# Visualize backgrounds\n",
    "def visualize_backgrounds(background_paths, num_samples=8):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    samples = random.sample(background_paths, min(num_samples, len(background_paths)))\n",
    "    \n",
    "    for i, path in enumerate(samples):\n",
    "        img = Image.open(path)\n",
    "        plt.subplot(2, 4, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Background {i+1}\")\n",
    "        plt.axis(\"off\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Generate and visualize backgrounds\n",
    "background_paths = create_background_images(200)\n",
    "visualize_backgrounds(background_paths)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Create Synthetic Dataset\n",
    "\n",
    "# %%\n",
    "def create_synthetic_dataset(background_paths, object_images, object_names, \n",
    "                            output_dir, split, img_size=(640, 640), num_images=500):\n",
    "    \"\"\"\n",
    "    Create a synthetic dataset by placing objects on backgrounds\n",
    "    \n",
    "    Parameters:\n",
    "        background_paths: List of paths to background images\n",
    "        object_images: List of object images with transparency\n",
    "        object_names: List of object class names\n",
    "        output_dir: Root directory to save dataset\n",
    "        split: Dataset split ('train', 'val', or 'test')\n",
    "        img_size: Size of output images (width, height)\n",
    "        num_images: Number of images to generate\n",
    "    \"\"\"\n",
    "    # Create directory structure\n",
    "    dataset_dir = os.path.join(output_dir, split)\n",
    "    images_dir = os.path.join(dataset_dir, \"images\")\n",
    "    labels_dir = os.path.join(dataset_dir, \"labels\")\n",
    "    \n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"üéØ Creating {num_images} synthetic images for {split} set...\")\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Select random background\n",
    "        bg_path = random.choice(background_paths)\n",
    "        try:\n",
    "            background = Image.open(bg_path).convert(\"RGB\").resize(img_size)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading background {bg_path}: {e}\")\n",
    "            # Create a simple background as fallback\n",
    "            background = Image.new(\"RGB\", img_size, (200, 200, 200))\n",
    "            \n",
    "        # Select random object\n",
    "        obj_idx = random.randint(0, len(object_images) - 1)\n",
    "        obj_image = object_images[obj_idx].copy()\n",
    "        \n",
    "        # Resize object to random size\n",
    "        scale_factor = random.uniform(0.1, 0.3)  # Object will be 10-30% of image size\n",
    "        obj_width = int(img_size[0] * scale_factor)\n",
    "        obj_height = int(obj_width * (obj_image.height / obj_image.width))  # Maintain aspect ratio\n",
    "        \n",
    "        try:\n",
    "            # For newer PIL versions\n",
    "            obj_image = obj_image.resize((obj_width, obj_height), Image.Resampling.LANCZOS)\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                # For older PIL versions\n",
    "                obj_image = obj_image.resize((obj_width, obj_height), Image.LANCZOS)\n",
    "            except:\n",
    "                # Fallback\n",
    "                obj_image = obj_image.resize((obj_width, obj_height))\n",
    "                \n",
    "        # Place object at random position\n",
    "        max_x = img_size[0] - obj_width\n",
    "        max_y = img_size[1] - obj_height\n",
    "        x_pos = random.randint(0, max_x)\n",
    "        y_pos = random.randint(0, max_y)\n",
    "        \n",
    "        # Paste object on background\n",
    "        background.paste(obj_image, (x_pos, y_pos), obj_image)\n",
    "        \n",
    "        # Calculate YOLO format bounding box\n",
    "        x_center = (x_pos + obj_width / 2) / img_size[0]\n",
    "        y_center = (y_pos + obj_height / 2) / img_size[1]\n",
    "        width = obj_width / img_size[0]\n",
    "        height = obj_height / img_size[1]\n",
    "        \n",
    "        # Save image with proper padding in filename\n",
    "        img_filename = f\"{i:05d}.jpg\"\n",
    "        background.save(os.path.join(images_dir, img_filename))\n",
    "        \n",
    "        # Save label in YOLO format\n",
    "        label_filename = f\"{i:05d}.txt\"\n",
    "        with open(os.path.join(labels_dir, label_filename), \"w\") as f:\n",
    "            f.write(f\"{obj_idx} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "            \n",
    "        # Show progress\n",
    "        if (i + 1) % 100 == 0 or i == num_images - 1:\n",
    "            print(f\"  Progress: {i+1}/{num_images} images created\")\n",
    "    \n",
    "    print(f\"‚úÖ Created {split} dataset with {num_images} images\")\n",
    "    return images_dir, labels_dir\n",
    "\n",
    "# Create all datasets\n",
    "def create_all_datasets(background_paths, object_images, object_names, output_dir=\"dataset\"):\n",
    "    \"\"\"Create train, validation, and test datasets\"\"\"\n",
    "    # Reduced dataset sizes for quicker execution in Colab/Kaggle\n",
    "    train_images, train_labels = create_synthetic_dataset(\n",
    "        background_paths, object_images, object_names, \n",
    "        output_dir, \"train\", num_images=1000\n",
    "    )\n",
    "    \n",
    "    val_images, val_labels = create_synthetic_dataset(\n",
    "        background_paths, object_images, object_names, \n",
    "        output_dir, \"val\", num_images=200\n",
    "    )\n",
    "    \n",
    "    test_images, test_labels = create_synthetic_dataset(\n",
    "        background_paths, object_images, object_names, \n",
    "        output_dir, \"test\", num_images=100\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'train': (train_images, train_labels),\n",
    "        'val': (val_images, val_labels),\n",
    "        'test': (test_images, test_labels)\n",
    "    }\n",
    "\n",
    "# Create the datasets\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "dataset_paths = create_all_datasets(background_paths, object_images, object_names, dataset_dir)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Define Dataset and Create DataLoaders\n",
    "\n",
    "# %%\n",
    "# Define the PyTorch Dataset class\n",
    "class ObjectDetectionDataset(Dataset):\n",
    "    def __init__(self, root_dir, split, num_classes, transform=None):\n",
    "        \"\"\"\n",
    "        Dataset for object detection\n",
    "        \n",
    "        Parameters:\n",
    "            root_dir: Root directory of the dataset\n",
    "            split: 'train', 'val', or 'test'\n",
    "            num_classes: Number of object classes\n",
    "            transform: PyTorch transformations to apply\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.split = split\n",
    "        self.num_classes = num_classes\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get the paths\n",
    "        self.images_dir = os.path.join(root_dir, split, \"images\")\n",
    "        self.labels_dir = os.path.join(root_dir, split, \"labels\")\n",
    "        \n",
    "        # Get image files\n",
    "        self.image_files = sorted([\n",
    "            f for f in os.listdir(self.images_dir) \n",
    "            if f.endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "        ])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_path = os.path.join(self.images_dir, self.image_files[idx])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Get corresponding label\n",
    "        label_path = os.path.join(self.labels_dir, \n",
    "                                  os.path.splitext(self.image_files[idx])[0] + \".txt\")\n",
    "        \n",
    "        # Default values in case label is missing\n",
    "        class_id = 0\n",
    "        bbox = torch.tensor([0.5, 0.5, 0.2, 0.2])  # [x_center, y_center, width, height]\n",
    "        \n",
    "        # Try to load label\n",
    "        try:\n",
    "            with open(label_path, \"r\") as f:\n",
    "                label_data = f.readline().strip().split()\n",
    "                class_id = int(float(label_data[0]))\n",
    "                bbox = torch.tensor([float(x) for x in label_data[1:5]])\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error loading label for {self.image_files[idx]}: {e}\")\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, bbox, class_id\n",
    "\n",
    "# Define transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create dataset objects\n",
    "train_dataset = ObjectDetectionDataset(dataset_dir, \"train\", len(object_names), train_transform)\n",
    "val_dataset = ObjectDetectionDataset(dataset_dir, \"val\", len(object_names), val_transform)\n",
    "test_dataset = ObjectDetectionDataset(dataset_dir, \"test\", len(object_names), test_transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"‚úÖ DataLoaders created\")\n",
    "print(f\"  ‚Ä¢ Train: {len(train_dataset)} images ({len(train_loader)} batches)\")\n",
    "print(f\"  ‚Ä¢ Val: {len(val_dataset)} images ({len(val_loader)} batches)\")\n",
    "print(f\"  ‚Ä¢ Test: {len(test_dataset)} images ({len(test_loader)} batches)\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 6. Visualize Training Samples\n",
    "\n",
    "# %%\n",
    "# Visualize dataset samples\n",
    "def visualize_dataset_sample(dataset, num_samples=4):\n",
    "    \"\"\"Visualize samples from the dataset\"\"\"\n",
    "    if len(dataset) == 0:\n",
    "        print(\"‚ùå No images in dataset to visualize\")\n",
    "        return\n",
    "        \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i in range(min(num_samples, len(dataset))):\n",
    "        image, bbox, class_id = dataset[i]\n",
    "        \n",
    "        # Denormalize the image\n",
    "        img = image.permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Extract bounding box\n",
    "        x_center, y_center, width, height = bbox.numpy()\n",
    "        \n",
    "        # Calculate bounding box corners\n",
    "        x_min = (x_center - width/2) * img.shape[1]\n",
    "        y_min = (y_center - height/2) * img.shape[0]\n",
    "        x_max = (x_center + width/2) * img.shape[1]\n",
    "        y_max = (y_center + height/2) * img.shape[0]\n",
    "        \n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"Class: {object_names[class_id]}\")\n",
    "        \n",
    "        # Draw bounding box\n",
    "        rect = plt.Rectangle((x_min, y_min), x_max-x_min, y_max-y_min, \n",
    "                           fill=False, edgecolor='red', linewidth=2)\n",
    "        plt.gca().add_patch(rect)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize samples from each dataset\n",
    "print(\"üñºÔ∏è Visualizing training samples:\")\n",
    "visualize_dataset_sample(train_dataset)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. Build Custom Object Detection Model\n",
    "\n",
    "# %%\n",
    "# Define the custom object detection model with a pre-trained backbone\n",
    "class CustomObjectDetectionModel(nn.Module):\n",
    "    def __init__(self, num_classes=3, pretrained=True):\n",
    "        super(CustomObjectDetectionModel, self).__init__()\n",
    "        # Use a pre-trained ResNet18 as the backbone\n",
    "        resnet = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Remove the final fully connected layer and avgpool\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-2])\n",
    "        \n",
    "        # Feature pyramid to handle multi-scale detection\n",
    "        self.conv1x1 = nn.Conv2d(512, 256, kernel_size=1)  # Reduce channels\n",
    "        \n",
    "        # Add spatial pyramid pooling to handle various object sizes\n",
    "        self.spp = nn.Sequential(\n",
    "            nn.AdaptiveMaxPool2d(5),  # Multi-scale features\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # Feature size after SPP and flattening\n",
    "        feature_size = 5 * 5 * 256\n",
    "        \n",
    "        # Classification head\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.Linear(feature_size, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),  # Add dropout for regularization\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Bounding box regression head\n",
    "        self.regression_head = nn.Sequential(\n",
    "            nn.Linear(feature_size, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),  # Add dropout for regularization\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 4),  # [x_center, y_center, width, height]\n",
    "            nn.Sigmoid()  # Bound outputs between 0 and 1 for normalized coordinates\n",
    "        )\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        # Initialize the weights of our added layers \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features from the backbone\n",
    "        features = self.backbone(x) \n",
    "        \n",
    "        # Apply 1x1 convolution to reduce channels\n",
    "        features = self.conv1x1(features)\n",
    "        \n",
    "        # Apply spatial pyramid pooling\n",
    "        features_flat = self.spp(features)\n",
    "        \n",
    "        # Process features through the classification and regression heads\n",
    "        class_logits = self.classification_head(features_flat)\n",
    "        bbox_coords = self.regression_head(features_flat)\n",
    "        \n",
    "        return class_logits, bbox_coords\n",
    "\n",
    "# Create the model\n",
    "num_classes = len(object_names)\n",
    "model = CustomObjectDetectionModel(num_classes=num_classes, pretrained=True).to(device)\n",
    "\n",
    "# Print model info\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "total_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {total_params:,}\")\n",
    "print(f\"Model created with {len(object_names)} classes\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Define Loss Function and Optimizer\n",
    "\n",
    "# %%\n",
    "# Define the loss functions\n",
    "classification_loss_fn = nn.CrossEntropyLoss()  # For class probabilities\n",
    "regression_loss_fn = nn.SmoothL1Loss()  # Better choice for bounding box regression than MSE\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Learning rate scheduler to reduce LR when training plateaus\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.1, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# Define a custom combined loss function\n",
    "def object_detection_loss(class_pred, bbox_pred, class_target, bbox_target):\n",
    "    \"\"\"\n",
    "    Calculate combined loss for object detection\n",
    "    \n",
    "    Args:\n",
    "        class_pred: predicted class scores [batch_size, num_classes]\n",
    "        bbox_pred: predicted bounding boxes [batch_size, 4]\n",
    "        class_target: ground truth class indices [batch_size]\n",
    "        bbox_target: ground truth bounding boxes [batch_size, 4]\n",
    "    \n",
    "    Returns:\n",
    "        total_loss: combined classification and regression loss\n",
    "        cls_loss: classification loss component\n",
    "        reg_loss: regression loss component\n",
    "    \"\"\"\n",
    "    # Calculate classification loss\n",
    "    cls_loss = classification_loss_fn(class_pred, class_target)\n",
    "    \n",
    "    # Calculate regression loss\n",
    "    reg_loss = regression_loss_fn(bbox_pred, bbox_target)\n",
    "    \n",
    "    # Combine losses - balanced weighting\n",
    "    total_loss = cls_loss + reg_loss\n",
    "    \n",
    "    return total_loss, cls_loss, reg_loss\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 9. Train the Model\n",
    "\n",
    "# %%\n",
    "# Function to train the object detection model\n",
    "def train_model(model, train_loader, val_loader, loss_fn, optimizer, scheduler, \n",
    "                num_epochs=10, early_stopping_patience=5, device=device):\n",
    "    \"\"\"\n",
    "    Train the custom object detection model\n",
    "    \n",
    "    Args:\n",
    "        model: The model to train\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        loss_fn: Combined loss function\n",
    "        optimizer: Optimizer for parameter updates\n",
    "        scheduler: Learning rate scheduler\n",
    "        num_epochs: Maximum number of epochs to train\n",
    "        early_stopping_patience: Number of epochs to wait before early stopping\n",
    "        device: Device to train on (cuda/cpu)\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained model\n",
    "        history: Training history (losses, metrics)\n",
    "    \"\"\"\n",
    "    # Initialize history dictionary to track metrics\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_cls_loss': [], 'val_cls_loss': [],\n",
    "        'train_reg_loss': [], 'val_reg_loss': []\n",
    "    }\n",
    "    \n",
    "    # Variables for early stopping and best model tracking\n",
    "    best_val_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "    best_model_path = 'best_model.pth'\n",
    "    \n",
    "    # Progress bar for epochs\n",
    "    print(f\"üèãÔ∏è Starting training for {num_epochs} epochs...\")\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_cls_loss = 0.0\n",
    "        train_reg_loss = 0.0\n",
    "        \n",
    "        # Progress bar for training\n",
    "        train_progress = tqdm(train_loader, desc=\"Training\", leave=False)\n",
    "        \n",
    "        for i, (images, bboxes, class_ids) in enumerate(train_progress):\n",
    "            # Move data to device\n",
    "            images = images.to(device)\n",
    "            bboxes = bboxes.to(device)\n",
    "            class_ids = class_ids.to(device)\n",
    "            \n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            class_pred, bbox_pred = model(images)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss, cls_loss, reg_loss = loss_fn(class_pred, bbox_pred, class_ids, bboxes)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update running losses\n",
    "            train_loss += loss.item()\n",
    "            train_cls_loss += cls_loss.item()\n",
    "            train_reg_loss += reg_loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_progress.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate average training losses\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_train_cls_loss = train_cls_loss / len(train_loader)\n",
    "        avg_train_reg_loss = train_reg_loss / len(train_loader)\n",
    "        \n",
    "        # Add to history\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_cls_loss'].append(avg_train_cls_loss)\n",
    "        history['train_reg_loss'].append(avg_train_reg_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_cls_loss = 0.0\n",
    "        val_reg_loss = 0.0\n",
    "        \n",
    "        # Progress bar for validation\n",
    "        val_progress = tqdm(val_loader, desc=\"Validation\", leave=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for i, (images, bboxes, class_ids) in enumerate(val_progress):\n",
    "                # Move data to device\n",
    "                images = images.to(device)\n",
    "                bboxes = bboxes.to(device)\n",
    "                class_ids = class_ids.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                class_pred, bbox_pred = model(images)\n",
    "                \n",
    "                # Calculate loss\n",
    "                loss, cls_loss, reg_loss = loss_fn(class_pred, bbox_pred, class_ids, bboxes)\n",
    "                \n",
    "                # Update running losses\n",
    "                val_loss += loss.item()\n",
    "                val_cls_loss += cls_loss.item()\n",
    "                val_reg_loss += reg_loss.item()\n",
    "                \n",
    "                # Update progress bar\n",
    "                val_progress.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "        \n",
    "        # Calculate average validation losses\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_val_cls_loss = val_cls_loss / len(val_loader)\n",
    "        avg_val_reg_loss = val_reg_loss / len(val_loader)\n",
    "        \n",
    "        # Add to history\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_cls_loss'].append(avg_val_cls_loss)\n",
    "        history['val_reg_loss'].append(avg_val_reg_loss)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f} (Cls: {avg_train_cls_loss:.4f}, Reg: {avg_train_reg_loss:.4f})\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f} (Cls: {avg_val_cls_loss:.4f}, Reg: {avg_val_reg_loss:.4f})\")\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            early_stopping_counter = 0\n",
    "            \n",
    "            # Save the best model\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': best_val_loss,\n",
    "                'history': history\n",
    "            }, best_model_path)\n",
    "            \n",
    "            print(f\"  ‚úÖ Model improved! Saved checkpoint to {best_model_path}\")\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            print(f\"  ‚ö†Ô∏è Model did not improve. Early stopping counter: {early_stopping_counter}/{early_stopping_patience}\")\n",
    "            \n",
    "            # Check if we should stop early\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(f\"  üõë Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "    \n",
    "    # Load the best model\n",
    "    checkpoint = torch.load(best_model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"\\n‚úÖ Training complete! Best model from epoch {checkpoint['epoch']} loaded (Val Loss: {checkpoint['val_loss']:.4f})\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# Set training parameters - reduced for Colab/Kaggle\n",
    "num_epochs = 10  # Use 20-30 if running on more powerful hardware\n",
    "early_stopping_patience = 3\n",
    "\n",
    "# Start training\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    loss_fn=object_detection_loss,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs,\n",
    "    early_stopping_patience=early_stopping_patience\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 10. Visualize Training Metrics\n",
    "\n",
    "# %%\n",
    "# Plot the training history\n",
    "def plot_training_metrics(history):\n",
    "    \"\"\"Plot training and validation metrics with analysis\"\"\"\n",
    "    # Create a figure with 2 subplots\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    # Plot total loss (main metric)\n",
    "    axes[0].plot(history['train_loss'], label=\"Training Loss\", color=\"blue\", marker=\"o\")\n",
    "    axes[0].plot(history['val_loss'], label=\"Validation Loss\", color=\"orange\", marker=\"o\")\n",
    "    axes[0].set_ylabel(\"Total Loss\")\n",
    "    axes[0].set_title(\"Training and Validation Loss Over Time\")\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "    \n",
    "    # Add annotations for best model\n",
    "    best_epoch = np.argmin(history['val_loss'])\n",
    "    best_val_loss = history['val_loss'][best_epoch]\n",
    "    axes[0].axvline(x=best_epoch, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[0].scatter(best_epoch, best_val_loss, s=100, c='red', label=f'Best Model (Epoch {best_epoch+1})')\n",
    "    \n",
    "    # Plot component losses (classification and regression)\n",
    "    axes[1].plot(history['train_cls_loss'], label=\"Train Classification Loss\", color=\"blue\", linestyle=\"-\")\n",
    "    axes[1].plot(history['val_cls_loss'], label=\"Val Classification Loss\", color=\"blue\", linestyle=\"--\")\n",
    "    axes[1].plot(history['train_reg_loss'], label=\"Train Regression Loss\", color=\"green\", linestyle=\"-\")\n",
    "    axes[1].plot(history['val_reg_loss'], label=\"Val Regression Loss\", color=\"green\", linestyle=\"--\")\n",
    "    axes[1].set_xlabel(\"Epochs\")\n",
    "    axes[1].set_ylabel(\"Component Losses\")\n",
    "    axes[1].set_title(\"Classification and Regression Loss Components\")\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze convergence and provide text report\n",
    "    print(\"üìä Model Convergence Analysis:\")\n",
    "    \n",
    "    # Check if the model has converged\n",
    "    min_loss_epoch = np.argmin(history['val_loss'])\n",
    "    last_epoch = len(history['val_loss']) - 1\n",
    "    \n",
    "    # Calculate training and validation loss reduction\n",
    "    initial_train_loss = history['train_loss'][0]\n",
    "    final_train_loss = history['train_loss'][last_epoch]\n",
    "    train_reduction = ((initial_train_loss - final_train_loss) / initial_train_loss) * 100\n",
    "    \n",
    "    initial_val_loss = history['val_loss'][0]\n",
    "    final_val_loss = history['val_loss'][last_epoch]\n",
    "    best_val_loss = history['val_loss'][min_loss_epoch]\n",
    "    val_reduction = ((initial_val_loss - best_val_loss) / initial_val_loss) * 100\n",
    "    \n",
    "    # Check if loss is still decreasing at the end of training\n",
    "    if min_loss_epoch == last_epoch:\n",
    "        print(f\"  ‚Ä¢ The model was STILL IMPROVING when training stopped at epoch {last_epoch+1}\")\n",
    "        print(f\"  ‚Ä¢ Consider training for more epochs to potentially achieve better performance\")\n",
    "    elif min_loss_epoch < last_epoch - 2:\n",
    "        print(f\"  ‚Ä¢ The model CONVERGED around epoch {min_loss_epoch+1} (best validation loss)\")\n",
    "        print(f\"  ‚Ä¢ Early stopping prevented overfitting by loading the best model\")\n",
    "    else:\n",
    "        print(f\"  ‚Ä¢ The model appears to have CONVERGED near the end of training (best at epoch {min_loss_epoch+1})\")\n",
    "    \n",
    "    print(f\"\\n  ‚Ä¢ Training loss reduced by {train_reduction:.2f}% (from {initial_train_loss:.4f} to {final_train_loss:.4f})\")\n",
    "    print(f\"  ‚Ä¢ Validation loss reduced by {val_reduction:.2f}% (from {initial_val_loss:.4f} to {best_val_loss:.4f})\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    if final_train_loss < final_val_loss * 0.7:\n",
    "        print(\"\\n  ‚ö†Ô∏è OVERFITTING DETECTED: The training loss is much lower than validation loss\")\n",
    "    else:\n",
    "        print(\"\\n  ‚úÖ HEALTHY CONVERGENCE: Training and validation losses decreased together\")\n",
    "        print(\"  ‚Ä¢ The model appears to generalize well to unseen data\")\n",
    "\n",
    "# Plot training metrics\n",
    "plot_training_metrics(history)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 11. Evaluate the Custom Model\n",
    "\n",
    "# %%\n",
    "# Function to calculate Intersection over Union (IoU)\n",
    "def calculate_iou(pred_box, true_box):\n",
    "    \"\"\"Calculate IoU between predicted and ground truth boxes in YOLO format\"\"\"\n",
    "    # Extract coordinates (convert from center format to corner format)\n",
    "    pred_x1 = pred_box[0] - pred_box[2] / 2\n",
    "    pred_y1 = pred_box[1] - pred_box[3] / 2\n",
    "    pred_x2 = pred_box[0] + pred_box[2] / 2\n",
    "    pred_y2 = pred_box[1] + pred_box[3] / 2\n",
    "\n",
    "    true_x1 = true_box[0] - true_box[2] / 2\n",
    "    true_y1 = true_box[1] - true_box[3] / 2\n",
    "    true_x2 = true_box[0] + true_box[2] / 2\n",
    "    true_y2 = true_box[1] + true_box[3] / 2\n",
    "\n",
    "    # Calculate intersection area\n",
    "    inter_x1 = max(pred_x1, true_x1)\n",
    "    inter_y1 = max(pred_y1, true_y1)\n",
    "    inter_x2 = min(pred_x2, true_x2)\n",
    "    inter_y2 = min(pred_y2, true_y2)\n",
    "\n",
    "    inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "\n",
    "    # Calculate union area\n",
    "    pred_area = (pred_x2 - pred_x1) * (pred_y2 - pred_y1)\n",
    "    true_area = (true_x2 - true_x1) * (true_y2 - true_y1)\n",
    "    union_area = pred_area + true_area - inter_area\n",
    "\n",
    "    # Avoid division by zero\n",
    "    if union_area == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return inter_area / union_area\n",
    "\n",
    "# Function to evaluate the model on the test set\n",
    "def evaluate_model(model, test_loader, device, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate the model on test data with multiple metrics\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Initialize metrics\n",
    "    metrics = {\n",
    "        'precision': [], 'recall': [], 'f1': [], 'iou': [],\n",
    "        'class_accuracy': [], 'inference_times': []\n",
    "    }\n",
    "    \n",
    "    # Class-specific metrics\n",
    "    class_metrics = {class_name: {'correct': 0, 'total': 0} \n",
    "                    for class_name in object_names}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, true_boxes, true_classes in test_loader:\n",
    "            images = images.to(device)\n",
    "            true_boxes = true_boxes.to(device)\n",
    "            true_classes = true_classes.to(device)\n",
    "            \n",
    "            # Measure inference time\n",
    "            start_time = time.time()\n",
    "            class_logits, pred_boxes = model(images)\n",
    "            end_time = time.time()\n",
    "            \n",
    "            # Calculate inference time per image\n",
    "            batch_inference_time = (end_time - start_time) / len(images)\n",
    "            metrics['inference_times'].append(batch_inference_time)\n",
    "            \n",
    "            # Get predicted classes\n",
    "            _, pred_classes = torch.max(class_logits, 1)\n",
    "            \n",
    "            # Calculate metrics for each image in the batch\n",
    "            for i in range(len(images)):\n",
    "                pred_box = pred_boxes[i].cpu().numpy()\n",
    "                true_box = true_boxes[i].cpu().numpy()\n",
    "                \n",
    "                # Calculate IoU\n",
    "                iou = calculate_iou(pred_box, true_box)\n",
    "                metrics['iou'].append(iou)\n",
    "                \n",
    "                # Class prediction accuracy\n",
    "                pred_class = pred_classes[i].item()\n",
    "                true_class = true_classes[i].item()\n",
    "                class_correct = (pred_class == true_class)\n",
    "                metrics['class_accuracy'].append(float(class_correct))\n",
    "                \n",
    "                # Update class-specific metrics\n",
    "                class_name = object_names[true_class]\n",
    "                class_metrics[class_name]['total'] += 1\n",
    "                if class_correct:\n",
    "                    class_metrics[class_name]['correct'] += 1\n",
    "                \n",
    "                # Calculate precision, recall, and F1-score\n",
    "                # Detection is correct if IoU > threshold AND class is correct\n",
    "                correct_detection = (iou > iou_threshold) and class_correct\n",
    "                \n",
    "                if correct_detection:\n",
    "                    precision = 1.0\n",
    "                    recall = 1.0\n",
    "                else:\n",
    "                    precision = 0.0\n",
    "                    recall = 0.0\n",
    "                \n",
    "                f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "                \n",
    "                metrics['precision'].append(precision)\n",
    "                metrics['recall'].append(recall)\n",
    "                metrics['f1'].append(f1)\n",
    "    \n",
    "    # Calculate mean metrics\n",
    "    mean_metrics = {\n",
    "        'precision': np.mean(metrics['precision']),\n",
    "        'recall': np.mean(metrics['recall']),\n",
    "        'f1': np.mean(metrics['f1']),\n",
    "        'iou': np.mean(metrics['iou']),\n",
    "        'class_accuracy': np.mean(metrics['class_accuracy']),\n",
    "        'inference_time': np.mean(metrics['inference_times'])\n",
    "    }\n",
    "    \n",
    "    # Calculate class-specific accuracy\n",
    "    for class_name in class_metrics:\n",
    "        total = class_metrics[class_name]['total']\n",
    "        if total > 0:\n",
    "            class_metrics[class_name]['accuracy'] = class_metrics[class_name]['correct'] / total\n",
    "        else:\n",
    "            class_metrics[class_name]['accuracy'] = 0.0\n",
    "    \n",
    "    # Calculate model size\n",
    "    model_size_bytes = sum(p.nelement() * p.element_size() for p in model.parameters())\n",
    "    model_size_mb = model_size_bytes / (1024 * 1024)\n",
    "    \n",
    "    # Print metrics summary\n",
    "    print(\"\\nüìä Model Evaluation Metrics:\")\n",
    "    print(f\"  ‚Ä¢ Mean Precision: {mean_metrics['precision']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Mean Recall: {mean_metrics['recall']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Mean F1-Score: {mean_metrics['f1']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Mean IoU: {mean_metrics['iou']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Class Prediction Accuracy: {mean_metrics['class_accuracy']:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Average Inference Time: {mean_metrics['inference_time']*1000:.2f} ms per image\")\n",
    "    print(f\"  ‚Ä¢ Model Size: {model_size_mb:.2f} MB\")\n",
    "    \n",
    "    # Print class-specific metrics\n",
    "    print(\"\\nüìä Class-Specific Metrics:\")\n",
    "    for class_name in class_metrics:\n",
    "        accuracy = class_metrics[class_name]['accuracy']\n",
    "        total = class_metrics[class_name]['total']\n",
    "        print(f\"  ‚Ä¢ {class_name}: Accuracy = {accuracy:.4f} (from {total} samples)\")\n",
    "    \n",
    "    return mean_metrics, class_metrics\n",
    "\n",
    "# Run evaluation on the test set\n",
    "mean_metrics, class_metrics = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 12. Visualize Custom Model Predictions\n",
    "\n",
    "# %%\n",
    "# Visualize predictions on test images\n",
    "def visualize_predictions(model, test_loader, device, num_images=8):\n",
    "    \"\"\"\n",
    "    Visualize model predictions vs ground truth with detailed metrics\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Get a batch from the test loader\n",
    "    data_iter = iter(test_loader)\n",
    "    images, true_boxes, true_classes = next(data_iter)\n",
    "    \n",
    "    # Ensure we don't try to visualize more images than we have\n",
    "    num_images = min(num_images, len(images))\n",
    "    \n",
    "    # Make predictions\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        class_logits, pred_boxes = model(images)\n",
    "        _, pred_classes = torch.max(class_logits, 1)\n",
    "    \n",
    "    # Set up the plot\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Get image and convert for display\n",
    "        img = images[i].cpu()\n",
    "        img = img.permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Get ground truth box and class\n",
    "        true_box = true_boxes[i].cpu().numpy()\n",
    "        true_class = true_classes[i].item()\n",
    "        true_class_name = object_names[true_class]\n",
    "        \n",
    "        # Get predicted box and class\n",
    "        pred_box = pred_boxes[i].cpu().numpy()\n",
    "        pred_class = pred_classes[i].item()\n",
    "        pred_class_name = object_names[pred_class]\n",
    "        \n",
    "        # Calculate IoU\n",
    "        iou = calculate_iou(pred_box, true_box)\n",
    "        \n",
    "        # Plot the image\n",
    "        axes[i].imshow(img)\n",
    "        \n",
    "        # Draw ground truth box (green)\n",
    "        x_center, y_center, width, height = true_box\n",
    "        x_min = (x_center - width/2) * img.shape[1]\n",
    "        y_min = (y_center - height/2) * img.shape[0]\n",
    "        x_max = (x_center + width/2) * img.shape[1]\n",
    "        y_max = (y_center + height/2) * img.shape[0]\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), x_max-x_min, y_max-y_min,\n",
    "            linewidth=2, edgecolor='green', facecolor='none', label='True'\n",
    "        )\n",
    "        axes[i].add_patch(rect)\n",
    "        \n",
    "        # Draw predicted box (red)\n",
    "        x_center, y_center, width, height = pred_box\n",
    "        x_min = (x_center - width/2) * img.shape[1]\n",
    "        y_min = (y_center - height/2) * img.shape[0]\n",
    "        x_max = (x_center + width/2) * img.shape[1]\n",
    "        y_max = (y_center + height/2) * img.shape[0]\n",
    "        \n",
    "        rect = patches.Rectangle(\n",
    "            (x_min, y_min), x_max-x_min, y_max-y_min,\n",
    "            linewidth=2, edgecolor='red', facecolor='none', label='Pred'\n",
    "        )\n",
    "        axes[i].add_patch(rect)\n",
    "        \n",
    "        # Add detailed title with metrics\n",
    "        axes[i].set_title(\n",
    "            f\"True: {true_class_name}, Pred: {pred_class_name}\\nIoU: {iou:.2f}\",\n",
    "            fontsize=10\n",
    "        )\n",
    "        axes[i].axis('off')\n",
    "        axes[i].legend()\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Model Predictions vs Ground Truth\", fontsize=16, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(model, test_loader, device)\n",
    "\n",
    "# Visualize predictions on test images with detailed metrics\n",
    "def visualize_predictions_with_metrics(model, test_loader, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Visualize model predictions on test images with detailed metrics\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    # Get a batch of images from the test loader\n",
    "    images, true_boxes, true_classes = next(iter(test_loader))\n",
    "    images, true_boxes, true_classes = images.to(device), true_boxes.to(device), true_classes.to(device)\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        class_logits, pred_boxes = model(images)\n",
    "        _, pred_classes = torch.max(class_logits, 1)\n",
    "\n",
    "    # Set up figure for visualization\n",
    "    num_images = min(8, len(images))\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Get current image and denormalize it properly\n",
    "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "        img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        # Display the image\n",
    "        axes[i].imshow(img)\n",
    "\n",
    "        # Get ground truth and prediction information\n",
    "        true_box = true_boxes[i].cpu().numpy()\n",
    "        pred_box = pred_boxes[i].cpu().numpy()\n",
    "        true_class = true_classes[i].item()\n",
    "        pred_class = pred_classes[i].item()\n",
    "        \n",
    "        # Get class names\n",
    "        true_class_name = object_names[true_class]\n",
    "        pred_class_name = object_names[pred_class]\n",
    "\n",
    "        # Calculate ground truth box coordinates\n",
    "        x_center, y_center, width, height = true_box\n",
    "        x_min = (x_center - width/2) * img.shape[1]\n",
    "        y_min = (y_center - height/2) * img.shape[0]\n",
    "        x_max = (x_center + width/2) * img.shape[1]\n",
    "        y_max = (y_center + height/2) * img.shape[0]\n",
    "        \n",
    "        # Add ground truth box\n",
    "        gt_rect = plt.Rectangle(\n",
    "            (x_min, y_min), x_max-x_min, y_max-y_min, \n",
    "            linewidth=2, edgecolor=\"green\", facecolor=\"none\", \n",
    "            label=f\"True: {true_class_name}\"\n",
    "        )\n",
    "        axes[i].add_patch(gt_rect)\n",
    "\n",
    "        # Calculate predicted box coordinates\n",
    "        x_center, y_center, width, height = pred_box\n",
    "        x_min = (x_center - width/2) * img.shape[1]\n",
    "        y_min = (y_center - height/2) * img.shape[0]\n",
    "        x_max = (x_center + width/2) * img.shape[1]\n",
    "        y_max = (y_center + height/2) * img.shape[0]\n",
    "        \n",
    "        # Add predicted box\n",
    "        pred_rect = plt.Rectangle(\n",
    "            (x_min, y_min), x_max-x_min, y_max-y_min, \n",
    "            linewidth=2, edgecolor=\"red\", facecolor=\"none\", \n",
    "            label=f\"Pred: {pred_class_name}\"\n",
    "        )\n",
    "        axes[i].add_patch(pred_rect)\n",
    "\n",
    "        # Calculate metrics\n",
    "        iou = calculate_iou(pred_box, true_box)\n",
    "        \n",
    "        # Calculate precision and recall based on IoU threshold\n",
    "        class_correct = (pred_class == true_class)\n",
    "        detection_correct = (iou > iou_threshold) and class_correct\n",
    "        \n",
    "        precision = 1.0 if detection_correct else 0.0\n",
    "        recall = 1.0 if detection_correct else 0.0\n",
    "        \n",
    "        # Add metrics annotation\n",
    "        axes[i].set_title(\n",
    "            f\"IoU: {iou:.2f} | Precision: {precision:.1f} | Recall: {recall:.1f}\\n\"\n",
    "            f\"True: {true_class_name} | Pred: {pred_class_name}\", \n",
    "            fontsize=9\n",
    "        )\n",
    "        axes[i].axis(\"off\")\n",
    "        axes[i].legend(loc=\"upper right\", fontsize=8)\n",
    "    \n",
    "    # Hide any unused subplots\n",
    "    for i in range(num_images, len(axes)):\n",
    "        axes[i].axis(\"off\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"Model Predictions vs Ground Truth with Metrics\", fontsize=14, y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Run the detailed visualization\n",
    "visualize_predictions_with_metrics(model, test_loader)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 13. Fine-tune YOLOv8 on the Same Dataset\n",
    "\n",
    "# %%\n",
    "# Prepare the data.yaml file for YOLO training\n",
    "train_images_path = os.path.join(dataset_dir, \"train\", \"images\")\n",
    "val_images_path = os.path.join(dataset_dir, \"val\", \"images\")\n",
    "test_images_path = os.path.join(dataset_dir, \"test\", \"images\")\n",
    "\n",
    "# Create the data.yaml file in the dataset directory\n",
    "data_yaml_path = os.path.join(dataset_dir, \"data.yaml\")\n",
    "with open(data_yaml_path, \"w\") as f:\n",
    "    f.write(f\"path: {dataset_dir}\\n\")\n",
    "    f.write(f\"train: {train_images_path}\\n\")\n",
    "    f.write(f\"val: {val_images_path}\\n\")\n",
    "    f.write(f\"test: {test_images_path}\\n\")\n",
    "    f.write(f\"nc: {len(object_names)}\\n\")  # Number of classes from object_names\n",
    "    \n",
    "    # Write class names dynamically from object_names\n",
    "    f.write(\"names:\\n\")\n",
    "    for i, name in enumerate(object_names):\n",
    "        f.write(f\"  {i}: {name}\\n\")\n",
    "\n",
    "print(f\"‚úÖ data.yaml file created at {data_yaml_path}\")\n",
    "print(\"üìÑ Content preview:\")\n",
    "with open(data_yaml_path, \"r\") as f:\n",
    "    print(f.read())\n",
    "\n",
    "# Import YOLO from ultralytics\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    # Load a pre-trained YOLO model\n",
    "    yolo_model = YOLO(\"yolov8n.pt\")  # Using YOLOv8 nano version\n",
    "    \n",
    "    # Print model information\n",
    "    print(f\"\\nüîç Using pre-trained model: YOLOv8n\")\n",
    "    print(f\"  ‚Ä¢ Architecture: YOLOv8 (Detection)\")\n",
    "    print(f\"  ‚Ä¢ Size: Nano (compact)\")\n",
    "    print(f\"  ‚Ä¢ Pre-trained on: COCO dataset (80 classes)\")\n",
    "    \n",
    "    # Fine-tune the YOLO model on the custom dataset\n",
    "    print(\"\\nüèãÔ∏è Starting YOLO model fine-tuning...\")\n",
    "    results = yolo_model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=5,  # Reduced for Colab/Kaggle\n",
    "        imgsz=640,\n",
    "        batch=8,  # Reduced for Colab/Kaggle\n",
    "        patience=3,  # Early stopping patience\n",
    "        save=True,  # Save best model\n",
    "        device=0 if torch.cuda.is_available() else \"cpu\",\n",
    "        project=\"yolo_training\",\n",
    "        name=\"run1\"\n",
    "    )\n",
    "    \n",
    "    # Save the fine-tuned YOLO model\n",
    "    fine_tuned_model_path = \"yolo_fine_tuned.pt\"\n",
    "    yolo_model.export(format=\"pytorch\")  # Export to PyTorch format\n",
    "    \n",
    "    print(f\"‚úÖ Fine-tuned YOLO model saved\")\n",
    "    print(f\"  ‚Ä¢ Best model path: {yolo_model.best}\")\n",
    "    print(f\"  ‚Ä¢ Exported model: {fine_tuned_model_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during YOLO training: {str(e)}\")\n",
    "    print(\"You can continue with the rest of the notebook.\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 14. Evaluate YOLO Model\n",
    "\n",
    "# %%\n",
    "# Function to evaluate the YOLO model on the test set\n",
    "def evaluate_yolo_model(yolo_model, test_loader):\n",
    "    \"\"\"\n",
    "    Evaluate YOLO model on test data and calculate standard metrics\n",
    "    \"\"\"\n",
    "    yolo_model.eval()  # Set YOLO model to evaluation mode\n",
    "    \n",
    "    # Initialize metrics\n",
    "    metrics = {\n",
    "        'precision': [], 'recall': [], 'f1': [], 'iou': [], \n",
    "        'inference_times': []\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, true_boxes, true_classes in test_loader:\n",
    "            # Process each image individually to avoid batching issues\n",
    "            for i in range(len(images)):\n",
    "                # Get single image and convert to numpy with correct format\n",
    "                image = images[i].cpu().numpy().transpose(1, 2, 0)  # CHW to HWC\n",
    "                \n",
    "                # Denormalize the image from [-1,1] to [0,255]\n",
    "                image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "                image = np.clip(image, 0, 1) * 255\n",
    "                image = image.astype(np.uint8)\n",
    "                \n",
    "                # Get ground truth\n",
    "                true_box = true_boxes[i].cpu().numpy()\n",
    "                true_class = true_classes[i].item()\n",
    "                \n",
    "                # Measure inference time for single image\n",
    "                start_time = time.time()\n",
    "                # Run inference with YOLO - process one image at a time\n",
    "                try:\n",
    "                    result = yolo_model(image, conf=0.25, iou=0.45)[0]  # Get first (only) result\n",
    "                    end_time = time.time()\n",
    "                    inference_time = end_time - start_time\n",
    "                    metrics['inference_times'].append(inference_time)\n",
    "                    \n",
    "                    # Get YOLO predictions (boxes in xywh normalized format)\n",
    "                    if len(result.boxes) > 0:\n",
    "                        # Convert to xywh normalized format\n",
    "                        pred_box = result.boxes.xywhn[0].cpu().numpy()\n",
    "                        pred_class = int(result.boxes.cls[0].item())\n",
    "                        \n",
    "                        # Calculate IoU between predicted and ground truth box\n",
    "                        iou = calculate_iou(pred_box, true_box)\n",
    "                        metrics['iou'].append(iou)\n",
    "                        \n",
    "                        # Determine if detection is correct (IoU > 0.5 and correct class)\n",
    "                        class_correct = (pred_class == true_class)\n",
    "                        detection_correct = (iou > 0.5) and class_correct\n",
    "                        \n",
    "                        # Calculate precision and recall\n",
    "                        precision = 1.0 if detection_correct else 0.0\n",
    "                        recall = 1.0 if detection_correct else 0.0\n",
    "                        \n",
    "                        # Calculate F1 score\n",
    "                        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "                    else:\n",
    "                        # No detection\n",
    "                        iou = 0.0\n",
    "                        precision = 0.0\n",
    "                        recall = 0.0\n",
    "                        f1 = 0.0\n",
    "                        metrics['iou'].append(iou)\n",
    "                    \n",
    "                    # Store metrics\n",
    "                    metrics['precision'].append(precision)\n",
    "                    metrics['recall'].append(recall)\n",
    "                    metrics['f1'].append(f1)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {i}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    # Calculate mean metrics if we have data\n",
    "    if len(metrics['iou']) > 0:\n",
    "        mean_metrics = {\n",
    "            'precision': np.mean(metrics['precision']),\n",
    "            'recall': np.mean(metrics['recall']),\n",
    "            'f1': np.mean(metrics['f1']),\n",
    "            'iou': np.mean(metrics['iou']),\n",
    "            'inference_time': np.mean(metrics['inference_times'])\n",
    "        }\n",
    "        \n",
    "        # Print detailed evaluation results\n",
    "        print(\"\\nüìä YOLO Model Evaluation Results:\")\n",
    "        print(f\"  ‚Ä¢ Mean Precision: {mean_metrics['precision']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Mean Recall: {mean_metrics['recall']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Mean F1-Score: {mean_metrics['f1']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Mean IoU: {mean_metrics['iou']:.4f}\")\n",
    "        print(f\"  ‚Ä¢ Average Inference Time: {mean_metrics['inference_time']*1000:.2f} ms per image\")\n",
    "    else:\n",
    "        print(\"‚ùå No detections made by the YOLO model\")\n",
    "        mean_metrics = None "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
