{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries for UI creation (tkinter), image processing (PIL, OpenCV), and deep learning (PyTorch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for UI creation, image processing, and deep learning\n",
    "\n",
    "import tkinter as tk  # For creating the UI\n",
    "from tkinter import filedialog, messagebox  # For file selection and alerts\n",
    "from PIL import Image, ImageTk  # For image processing and displaying in the UI\n",
    "import cv2  # For image manipulation and OpenCV operations\n",
    "import torch  # For deep learning model handling\n",
    "import torchvision.transforms as transforms  # For preprocessing images for the model\n",
    "import numpy as np  # For numerical operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define UI Components\n",
    "Create the UI components including image upload area, detection controls, and result display using tkinter or ipywidgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the UI components for testing the object detection model\n",
    "\n",
    "class ObjectDetectionUI:\n",
    "    def __init__(self, root, model, class_names):\n",
    "        self.root = root\n",
    "        self.model = model\n",
    "        self.class_names = class_names\n",
    "        self.image = None\n",
    "        self.processed_image = None\n",
    "\n",
    "        # Configure the main window\n",
    "        self.root.title(\"Object Detection Model Tester\")\n",
    "        self.root.geometry(\"800x600\")\n",
    "        self.root.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "        # Create UI components\n",
    "        self.create_image_upload_area()\n",
    "        self.create_detection_controls()\n",
    "        self.create_result_display()\n",
    "\n",
    "    def create_image_upload_area(self):\n",
    "        \"\"\"Create the image upload area.\"\"\"\n",
    "        frame = tk.Frame(self.root, bg=\"#f0f0f0\", pady=10)\n",
    "        frame.pack(fill=tk.X)\n",
    "\n",
    "        upload_button = tk.Button(\n",
    "            frame, text=\"Upload Image\", command=self.upload_image, bg=\"#4CAF50\", fg=\"white\", padx=10, pady=5\n",
    "        )\n",
    "        upload_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        self.image_label = tk.Label(frame, text=\"No image uploaded\", bg=\"#f0f0f0\", fg=\"#555\")\n",
    "        self.image_label.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "    def create_detection_controls(self):\n",
    "        \"\"\"Create the detection controls.\"\"\"\n",
    "        frame = tk.Frame(self.root, bg=\"#f0f0f0\", pady=10)\n",
    "        frame.pack(fill=tk.X)\n",
    "\n",
    "        detect_button = tk.Button(\n",
    "            frame, text=\"Run Detection\", command=self.run_detection, bg=\"#2196F3\", fg=\"white\", padx=10, pady=5\n",
    "        )\n",
    "        detect_button.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        self.confidence_label = tk.Label(frame, text=\"Confidence Threshold:\", bg=\"#f0f0f0\", fg=\"#555\")\n",
    "        self.confidence_label.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "        self.confidence_slider = tk.Scale(\n",
    "            frame, from_=0.1, to=1.0, resolution=0.1, orient=tk.HORIZONTAL, bg=\"#f0f0f0\", fg=\"#555\"\n",
    "        )\n",
    "        self.confidence_slider.set(0.5)\n",
    "        self.confidence_slider.pack(side=tk.LEFT, padx=10)\n",
    "\n",
    "    def create_result_display(self):\n",
    "        \"\"\"Create the result display area.\"\"\"\n",
    "        frame = tk.Frame(self.root, bg=\"#f0f0f0\", pady=10)\n",
    "        frame.pack(fill=tk.BOTH, expand=True)\n",
    "\n",
    "        self.canvas = tk.Canvas(frame, bg=\"#ffffff\", width=600, height=400)\n",
    "        self.canvas.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "\n",
    "    def upload_image(self):\n",
    "        \"\"\"Handle image upload.\"\"\"\n",
    "        file_path = filedialog.askopenfilename(\n",
    "            title=\"Select an Image\", filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")]\n",
    "        )\n",
    "        if file_path:\n",
    "            self.image = Image.open(file_path)\n",
    "            self.image_label.config(text=f\"Uploaded: {file_path.split('/')[-1]}\")\n",
    "            self.display_image(self.image)\n",
    "\n",
    "    def display_image(self, image):\n",
    "        \"\"\"Display the uploaded image on the canvas.\"\"\"\n",
    "        self.processed_image = image.resize((600, 400), Image.ANTIALIAS)\n",
    "        self.tk_image = ImageTk.PhotoImage(self.processed_image)\n",
    "        self.canvas.create_image(300, 200, image=self.tk_image, anchor=tk.CENTER)\n",
    "\n",
    "    def run_detection(self):\n",
    "        \"\"\"Run object detection on the uploaded image.\"\"\"\n",
    "        if self.image is None:\n",
    "            messagebox.showerror(\"Error\", \"Please upload an image first.\")\n",
    "            return\n",
    "\n",
    "        # Preprocess the image\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        input_image = transform(self.image).unsqueeze(0)\n",
    "\n",
    "        # Run the model\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_image)\n",
    "\n",
    "        # Process the outputs\n",
    "        self.display_results(outputs)\n",
    "\n",
    "    def display_results(self, outputs):\n",
    "        \"\"\"Display the detection results on the canvas.\"\"\"\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.canvas.create_image(300, 200, image=self.tk_image, anchor=tk.CENTER)\n",
    "\n",
    "        for output in outputs[0]:\n",
    "            x1, y1, x2, y2, conf, class_id = output\n",
    "            if conf >= self.confidence_slider.get():\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                self.canvas.create_rectangle(x1, y1, x2, y2, outline=\"red\", width=2)\n",
    "                self.canvas.create_text(\n",
    "                    x1, y1 - 10, text=f\"{self.class_names[int(class_id)]} ({conf:.2f})\", fill=\"red\", anchor=tk.W\n",
    "                )\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# root = tk.Tk()\n",
    "# model = ...  # Load your PyTorch model here\n",
    "# class_names = [\"class1\", \"class2\", \"class3\"]  # Replace with your class names\n",
    "# app = ObjectDetectionUI(root, model, class_names)\n",
    "# root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "Define functions to load and prepare the pre-trained object detection model. Include options to load different models (custom model and YOLO)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_type=\"custom\", model_path=None):\n",
    "    \"\"\"\n",
    "    Load and prepare the object detection model.\n",
    "\n",
    "    Parameters:\n",
    "        model_type (str): Type of model to load (\"custom\" or \"yolo\").\n",
    "        model_path (str): Path to the custom model file (if applicable).\n",
    "\n",
    "    Returns:\n",
    "        model: Loaded PyTorch model.\n",
    "        class_names (list): List of class names for the model.\n",
    "    \"\"\"\n",
    "    if model_type == \"custom\":\n",
    "        if model_path is None:\n",
    "            raise ValueError(\"Please provide the path to the custom model.\")\n",
    "        try:\n",
    "            # Load the custom model\n",
    "            model = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "            model.eval()\n",
    "            print(f\"✅ Custom model loaded from {model_path}\")\n",
    "            # Define class names (update based on your dataset)\n",
    "            class_names = [\"class1\", \"class2\", \"class3\"]\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load custom model: {e}\")\n",
    "    elif model_type == \"yolo\":\n",
    "        try:\n",
    "            # Load a pre-trained YOLO model from torchvision\n",
    "            model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", pretrained=True)\n",
    "            model.eval()\n",
    "            print(\"✅ YOLO model loaded successfully\")\n",
    "            # Define class names for YOLO\n",
    "            class_names = model.names\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to load YOLO model: {e}\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model type. Choose 'custom' or 'yolo'.\")\n",
    "\n",
    "    return model, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Detection Logic\n",
    "Implement the core detection functionality that processes images, runs inference with the model, and extracts bounding boxes with confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(image, model, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Detect objects in an image using the provided model.\n",
    "\n",
    "    Parameters:\n",
    "        image (PIL.Image): The input image.\n",
    "        model (torch.nn.Module): The object detection model.\n",
    "        confidence_threshold (float): Minimum confidence score to consider a detection.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of detections, where each detection is a tuple (x1, y1, x2, y2, confidence, class_id).\n",
    "    \"\"\"\n",
    "    # Preprocess the image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    input_image = transform(image).unsqueeze(0)\n",
    "\n",
    "    # Run the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_image)\n",
    "\n",
    "    # Process the outputs\n",
    "    detections = []\n",
    "    for output in outputs[0]:  # Assuming the model returns a list of detections\n",
    "        x1, y1, x2, y2, conf, class_id = output\n",
    "        if conf >= confidence_threshold:\n",
    "            detections.append((x1, y1, x2, y2, conf, class_id))\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Launch the UI\n",
    "Assemble all UI components and connect them to the detection logic. Set up event handlers for user interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     exit()\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Create the Object Detection UI\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m app \u001b[38;5;241m=\u001b[39m ObjectDetectionUI(root, \u001b[43mmodel\u001b[49m, class_names)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Start the Tkinter event loop\u001b[39;00m\n\u001b[0;32m     20\u001b[0m root\u001b[38;5;241m.\u001b[39mmainloop()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Build and Launch the UI\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize the main Tkinter window\n",
    "    root = tk.Tk()\n",
    "\n",
    "    # Load the model and class names\n",
    "    try:\n",
    "        # Replace 'custom_model.pth' with the path to your model file\n",
    "        model, class_names = load_model(model_type=\"custom\", model_path=\"custom_model.pth\")\n",
    "    except Exception as e:\n",
    "        messagebox.showerror(\"Error\", f\"Failed to load model: {e}\")\n",
    "        root.destroy()\n",
    "        exit()\n",
    "\n",
    "    # Create the Object Detection UI\n",
    "    app = ObjectDetectionUI(root, model, class_names)\n",
    "\n",
    "    # Start the Tkinter event loop\n",
    "    root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Visualization Functions\n",
    "Create functions to visualize detection results by drawing bounding boxes and labels on images with appropriate color coding based on confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detections(image, detections, class_names, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Visualize detection results by drawing bounding boxes and labels on the image.\n",
    "\n",
    "    Parameters:\n",
    "        image (PIL.Image): The input image.\n",
    "        detections (list): List of detections, where each detection is a tuple (x1, y1, x2, y2, confidence, class_id).\n",
    "        class_names (list): List of class names corresponding to class IDs.\n",
    "        confidence_threshold (float): Minimum confidence score to display a detection.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The image with bounding boxes and labels drawn.\n",
    "    \"\"\"\n",
    "    # Convert the image to a NumPy array for OpenCV processing\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    # Iterate through detections and draw bounding boxes and labels\n",
    "    for x1, y1, x2, y2, conf, class_id in detections:\n",
    "        if conf >= confidence_threshold:\n",
    "            # Convert coordinates to integers\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Define the color for the bounding box (based on class ID)\n",
    "            color = (0, 255, 0)  # Green for high confidence\n",
    "            if conf < 0.75:\n",
    "                color = (0, 255, 255)  # Yellow for medium confidence\n",
    "            if conf < 0.5:\n",
    "                color = (0, 0, 255)  # Red for low confidence\n",
    "\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(image_np, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "            # Prepare the label text\n",
    "            label = f\"{class_names[int(class_id)]}: {conf:.2f}\"\n",
    "\n",
    "            # Calculate text size and position\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            label_y = max(y1 - text_height - baseline, 0)\n",
    "\n",
    "            # Draw a filled rectangle for the label background\n",
    "            cv2.rectangle(image_np, (x1, label_y), (x1 + text_width, label_y + text_height + baseline), color, -1)\n",
    "\n",
    "            # Put the label text\n",
    "            cv2.putText(image_np, label, (x1, label_y + text_height), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "\n",
    "    # Convert the image back to PIL format\n",
    "    return Image.fromarray(image_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
